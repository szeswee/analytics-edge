{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question un\n",
    "### Part 1A (checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1232 obs. of  13 variables:\n",
      " $ Team        : Factor w/ 39 levels \"ANA\",\"ARI\",\"ATL\",..: 2 3 4 5 7 8 9 10 11 12 ...\n",
      " $ League      : Factor w/ 2 levels \"AL\",\"NL\": 2 2 1 1 2 1 2 1 2 1 ...\n",
      " $ Year        : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...\n",
      " $ RS          : int  734 700 712 734 613 748 669 667 758 726 ...\n",
      " $ RA          : int  688 600 705 806 759 676 588 845 890 670 ...\n",
      " $ W           : int  81 94 93 69 61 85 97 68 64 88 ...\n",
      " $ OBP         : num  0.328 0.32 0.311 0.315 0.302 0.318 0.315 0.324 0.33 0.335 ...\n",
      " $ SLG         : num  0.418 0.389 0.417 0.415 0.378 0.422 0.411 0.381 0.436 0.422 ...\n",
      " $ BA          : num  0.259 0.247 0.247 0.26 0.24 0.255 0.251 0.251 0.274 0.268 ...\n",
      " $ Playoffs    : int  0 1 1 0 0 0 1 0 0 1 ...\n",
      " $ RankSeason  : int  NA 4 5 NA NA NA 2 NA NA 6 ...\n",
      " $ RankPlayoffs: int  NA 5 4 NA NA NA 4 NA NA 2 ...\n",
      " $ Games       : int  162 162 162 162 162 162 162 162 162 162 ...\n",
      "\n",
      "No. of team/year pairs: 1232"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1973 1974 1975 1976 1977 1978 \n",
       "  20   20   20   20   20   20   20   24   24   24   24   24   24   24   26   26 \n",
       "1979 1980 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1996 1997 \n",
       "  26   26   26   26   26   26   26   26   26   26   26   26   26   28   28   28 \n",
       "1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 \n",
       "  30   30   30   30   30   30   30   30   30   30   30   30   30   30   30 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of years in dataset: 47\n",
      "No. of team/year pairs (subset): 244"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  4  8 10 \n",
       " 7 23 16  1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=7, repr.plot.height=4) # resize IRkernel plot size\n",
    "baseball <- read.csv(\"csv/baseballlarge.csv\")\n",
    "str(baseball)\n",
    "\n",
    "# part i\n",
    "# min(year)=1962 , max(year)=2012 , no. of years=51\n",
    "# total no. of team/year pairs in dataset\n",
    "cat(sprintf(\"\\nNo. of team/year pairs: %s\",\n",
    "            length(with(baseball, paste(Team, Year, sep=\" \")))))\n",
    "\n",
    "# part ii\n",
    "# total no. of years in dataset\n",
    "table(baseball$Year)\n",
    "cat(sprintf(\"\\nNo. of years in dataset: %s\",\n",
    "            length(table(baseball$Year))))\n",
    "\n",
    "# part iii\n",
    "# total no. of team/year pairs in subset\n",
    "baseballP <- subset(baseball, Playoffs==1)\n",
    "cat(sprintf(\"\\nNo. of team/year pairs (subset): %s\",\n",
    "            length(with(baseballP, paste(Team, Year, sep=\" \")))))\n",
    "\n",
    "# part iv\n",
    "# no. of teams invited to playoffs each year\n",
    "table(table(baseballP$Year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1B (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t244 obs. of  14 variables:\n",
      " $ Team        : Factor w/ 39 levels \"ANA\",\"ARI\",\"ATL\",..: 3 4 9 12 25 26 32 33 36 39 ...\n",
      " $ League      : Factor w/ 2 levels \"AL\",\"NL\": 2 1 2 1 1 1 2 2 1 2 ...\n",
      " $ Year        : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...\n",
      " $ RS          : int  700 712 669 726 804 713 718 765 808 731 ...\n",
      " $ RA          : int  600 705 588 670 668 614 649 648 707 594 ...\n",
      " $ W           : int  94 93 97 88 95 94 94 88 93 98 ...\n",
      " $ OBP         : num  0.32 0.311 0.315 0.335 0.337 0.31 0.327 0.338 0.334 0.322 ...\n",
      " $ SLG         : num  0.389 0.417 0.411 0.422 0.453 0.404 0.397 0.421 0.446 0.428 ...\n",
      " $ BA          : num  0.247 0.247 0.251 0.268 0.265 0.238 0.269 0.271 0.273 0.261 ...\n",
      " $ Playoffs    : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ RankSeason  : int  4 5 2 6 3 4 4 6 5 1 ...\n",
      " $ RankPlayoffs: int  5 4 4 2 3 4 1 3 5 4 ...\n",
      " $ Games       : int  162 162 162 162 162 162 162 162 162 162 ...\n",
      " $ NumComp     : int  10 10 10 10 10 10 10 10 10 10 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'2'</li>\n",
       "\t<li>'3'</li>\n",
       "\t<li>'7'</li>\n",
       "\t<li>'10'</li>\n",
       "\t<li>'19'</li>\n",
       "\t<li>'20'</li>\n",
       "\t<li>'25'</li>\n",
       "\t<li>'26'</li>\n",
       "\t<li>'28'</li>\n",
       "\t<li>'30'</li>\n",
       "\t<li>'31'</li>\n",
       "\t<li>'40'</li>\n",
       "\t<li>'46'</li>\n",
       "\t<li>'49'</li>\n",
       "\t<li>'51'</li>\n",
       "\t<li>'56'</li>\n",
       "\t<li>'57'</li>\n",
       "\t<li>'58'</li>\n",
       "\t<li>'62'</li>\n",
       "\t<li>'67'</li>\n",
       "\t<li>'77'</li>\n",
       "\t<li>'79'</li>\n",
       "\t<li>'81'</li>\n",
       "\t<li>'85'</li>\n",
       "\t<li>'87'</li>\n",
       "\t<li>'88'</li>\n",
       "\t<li>'94'</li>\n",
       "\t<li>'99'</li>\n",
       "\t<li>'104'</li>\n",
       "\t<li>'105'</li>\n",
       "\t<li>'107'</li>\n",
       "\t<li>'109'</li>\n",
       "\t<li>'111'</li>\n",
       "\t<li>'116'</li>\n",
       "\t<li>'124'</li>\n",
       "\t<li>'125'</li>\n",
       "\t<li>'126'</li>\n",
       "\t<li>'134'</li>\n",
       "\t<li>'135'</li>\n",
       "\t<li>'136'</li>\n",
       "\t<li>'141'</li>\n",
       "\t<li>'147'</li>\n",
       "\t<li>'151'</li>\n",
       "\t<li>'154'</li>\n",
       "\t<li>'155'</li>\n",
       "\t<li>'158'</li>\n",
       "\t<li>'159'</li>\n",
       "\t<li>'164'</li>\n",
       "\t<li>'169'</li>\n",
       "\t<li>'171'</li>\n",
       "\t<li>'190'</li>\n",
       "\t<li>'195'</li>\n",
       "\t<li>'197'</li>\n",
       "\t<li>'198'</li>\n",
       "\t<li>'199'</li>\n",
       "\t<li>'200'</li>\n",
       "\t<li>'203'</li>\n",
       "\t<li>'206'</li>\n",
       "\t<li>'212'</li>\n",
       "\t<li>'214'</li>\n",
       "\t<li>'216'</li>\n",
       "\t<li>'222'</li>\n",
       "\t<li>'224'</li>\n",
       "\t<li>'229'</li>\n",
       "\t<li>'233'</li>\n",
       "\t<li>'236'</li>\n",
       "\t<li>'241'</li>\n",
       "\t<li>'243'</li>\n",
       "\t<li>'245'</li>\n",
       "\t<li>'253'</li>\n",
       "\t<li>'255'</li>\n",
       "\t<li>'257'</li>\n",
       "\t<li>'260'</li>\n",
       "\t<li>'267'</li>\n",
       "\t<li>'273'</li>\n",
       "\t<li>'275'</li>\n",
       "\t<li>'276'</li>\n",
       "\t<li>'282'</li>\n",
       "\t<li>'287'</li>\n",
       "\t<li>'290'</li>\n",
       "\t<li>'291'</li>\n",
       "\t<li>'296'</li>\n",
       "\t<li>'301'</li>\n",
       "\t<li>'302'</li>\n",
       "\t<li>'303'</li>\n",
       "\t<li>'317'</li>\n",
       "\t<li>'320'</li>\n",
       "\t<li>'321'</li>\n",
       "\t<li>'326'</li>\n",
       "\t<li>'327'</li>\n",
       "\t<li>'332'</li>\n",
       "\t<li>'333'</li>\n",
       "\t<li>'339'</li>\n",
       "\t<li>'343'</li>\n",
       "\t<li>'350'</li>\n",
       "\t<li>'351'</li>\n",
       "\t<li>'355'</li>\n",
       "\t<li>'357'</li>\n",
       "\t<li>'363'</li>\n",
       "\t<li>'367'</li>\n",
       "\t<li>'379'</li>\n",
       "\t<li>'380'</li>\n",
       "\t<li>'381'</li>\n",
       "\t<li>'385'</li>\n",
       "\t<li>'386'</li>\n",
       "\t<li>'387'</li>\n",
       "\t<li>'392'</li>\n",
       "\t<li>'393'</li>\n",
       "\t<li>'395'</li>\n",
       "\t<li>'399'</li>\n",
       "\t<li>'403'</li>\n",
       "\t<li>'409'</li>\n",
       "\t<li>'410'</li>\n",
       "\t<li>'419'</li>\n",
       "\t<li>'423'</li>\n",
       "\t<li>'425'</li>\n",
       "\t<li>'426'</li>\n",
       "\t<li>'429'</li>\n",
       "\t<li>'433'</li>\n",
       "\t<li>'440'</li>\n",
       "\t<li>'444'</li>\n",
       "\t<li>'449'</li>\n",
       "\t<li>'452'</li>\n",
       "\t<li>'453'</li>\n",
       "\t<li>'458'</li>\n",
       "\t<li>'461'</li>\n",
       "\t<li>'462'</li>\n",
       "\t<li>'469'</li>\n",
       "\t<li>'474'</li>\n",
       "\t<li>'475'</li>\n",
       "\t<li>'479'</li>\n",
       "\t<li>'480'</li>\n",
       "\t<li>'486'</li>\n",
       "\t<li>'492'</li>\n",
       "\t<li>'497'</li>\n",
       "\t<li>'501'</li>\n",
       "\t<li>'504'</li>\n",
       "\t<li>'505'</li>\n",
       "\t<li>'507'</li>\n",
       "\t<li>'512'</li>\n",
       "\t<li>'527'</li>\n",
       "\t<li>'534'</li>\n",
       "\t<li>'535'</li>\n",
       "\t<li>'552'</li>\n",
       "\t<li>'554'</li>\n",
       "\t<li>'560'</li>\n",
       "\t<li>'561'</li>\n",
       "\t<li>'574'</li>\n",
       "\t<li>'580'</li>\n",
       "\t<li>'586'</li>\n",
       "\t<li>'589'</li>\n",
       "\t<li>'593'</li>\n",
       "\t<li>'604'</li>\n",
       "\t<li>'606'</li>\n",
       "\t<li>'617'</li>\n",
       "\t<li>'630'</li>\n",
       "\t<li>'635'</li>\n",
       "\t<li>'638'</li>\n",
       "\t<li>'641'</li>\n",
       "\t<li>'650'</li>\n",
       "\t<li>'654'</li>\n",
       "\t<li>'656'</li>\n",
       "\t<li>'673'</li>\n",
       "\t<li>'678'</li>\n",
       "\t<li>'687'</li>\n",
       "\t<li>'688'</li>\n",
       "\t<li>'693'</li>\n",
       "\t<li>'694'</li>\n",
       "\t<li>'700'</li>\n",
       "\t<li>'706'</li>\n",
       "\t<li>'727'</li>\n",
       "\t<li>'728'</li>\n",
       "\t<li>'740'</li>\n",
       "\t<li>'742'</li>\n",
       "\t<li>'747'</li>\n",
       "\t<li>'751'</li>\n",
       "\t<li>'753'</li>\n",
       "\t<li>'763'</li>\n",
       "\t<li>'770'</li>\n",
       "\t<li>'774'</li>\n",
       "\t<li>'780'</li>\n",
       "\t<li>'787'</li>\n",
       "\t<li>'795'</li>\n",
       "\t<li>'798'</li>\n",
       "\t<li>'807'</li>\n",
       "\t<li>'818'</li>\n",
       "\t<li>'830'</li>\n",
       "\t<li>'831'</li>\n",
       "\t<li>'837'</li>\n",
       "\t<li>'839'</li>\n",
       "\t<li>'848'</li>\n",
       "\t<li>'850'</li>\n",
       "\t<li>'853'</li>\n",
       "\t<li>'866'</li>\n",
       "\t<li>'883'</li>\n",
       "\t<li>'884'</li>\n",
       "\t<li>'889'</li>\n",
       "\t<li>'891'</li>\n",
       "\t<li>'909'</li>\n",
       "\t<li>'910'</li>\n",
       "\t<li>'915'</li>\n",
       "\t<li>'917'</li>\n",
       "\t<li>'931'</li>\n",
       "\t<li>'935'</li>\n",
       "\t<li>'941'</li>\n",
       "\t<li>'943'</li>\n",
       "\t<li>'951'</li>\n",
       "\t<li>'955'</li>\n",
       "\t<li>'966'</li>\n",
       "\t<li>'968'</li>\n",
       "\t<li>'974'</li>\n",
       "\t<li>'984'</li>\n",
       "\t<li>'990'</li>\n",
       "\t<li>'992'</li>\n",
       "\t<li>'998'</li>\n",
       "\t<li>'1003'</li>\n",
       "\t<li>'1012'</li>\n",
       "\t<li>'1014'</li>\n",
       "\t<li>'1022'</li>\n",
       "\t<li>'1038'</li>\n",
       "\t<li>'1040'</li>\n",
       "\t<li>'1042'</li>\n",
       "\t<li>'1046'</li>\n",
       "\t<li>'1051'</li>\n",
       "\t<li>'1058'</li>\n",
       "\t<li>'1064'</li>\n",
       "\t<li>'1069'</li>\n",
       "\t<li>'1070'</li>\n",
       "\t<li>'1081'</li>\n",
       "\t<li>'1083'</li>\n",
       "\t<li>'1101'</li>\n",
       "\t<li>'1111'</li>\n",
       "\t<li>'1115'</li>\n",
       "\t<li>'1131'</li>\n",
       "\t<li>'1134'</li>\n",
       "\t<li>'1144'</li>\n",
       "\t<li>'1163'</li>\n",
       "\t<li>'1164'</li>\n",
       "\t<li>'1187'</li>\n",
       "\t<li>'1191'</li>\n",
       "\t<li>'1203'</li>\n",
       "\t<li>'1207'</li>\n",
       "\t<li>'1227'</li>\n",
       "\t<li>'1230'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '2'\n",
       "\\item '3'\n",
       "\\item '7'\n",
       "\\item '10'\n",
       "\\item '19'\n",
       "\\item '20'\n",
       "\\item '25'\n",
       "\\item '26'\n",
       "\\item '28'\n",
       "\\item '30'\n",
       "\\item '31'\n",
       "\\item '40'\n",
       "\\item '46'\n",
       "\\item '49'\n",
       "\\item '51'\n",
       "\\item '56'\n",
       "\\item '57'\n",
       "\\item '58'\n",
       "\\item '62'\n",
       "\\item '67'\n",
       "\\item '77'\n",
       "\\item '79'\n",
       "\\item '81'\n",
       "\\item '85'\n",
       "\\item '87'\n",
       "\\item '88'\n",
       "\\item '94'\n",
       "\\item '99'\n",
       "\\item '104'\n",
       "\\item '105'\n",
       "\\item '107'\n",
       "\\item '109'\n",
       "\\item '111'\n",
       "\\item '116'\n",
       "\\item '124'\n",
       "\\item '125'\n",
       "\\item '126'\n",
       "\\item '134'\n",
       "\\item '135'\n",
       "\\item '136'\n",
       "\\item '141'\n",
       "\\item '147'\n",
       "\\item '151'\n",
       "\\item '154'\n",
       "\\item '155'\n",
       "\\item '158'\n",
       "\\item '159'\n",
       "\\item '164'\n",
       "\\item '169'\n",
       "\\item '171'\n",
       "\\item '190'\n",
       "\\item '195'\n",
       "\\item '197'\n",
       "\\item '198'\n",
       "\\item '199'\n",
       "\\item '200'\n",
       "\\item '203'\n",
       "\\item '206'\n",
       "\\item '212'\n",
       "\\item '214'\n",
       "\\item '216'\n",
       "\\item '222'\n",
       "\\item '224'\n",
       "\\item '229'\n",
       "\\item '233'\n",
       "\\item '236'\n",
       "\\item '241'\n",
       "\\item '243'\n",
       "\\item '245'\n",
       "\\item '253'\n",
       "\\item '255'\n",
       "\\item '257'\n",
       "\\item '260'\n",
       "\\item '267'\n",
       "\\item '273'\n",
       "\\item '275'\n",
       "\\item '276'\n",
       "\\item '282'\n",
       "\\item '287'\n",
       "\\item '290'\n",
       "\\item '291'\n",
       "\\item '296'\n",
       "\\item '301'\n",
       "\\item '302'\n",
       "\\item '303'\n",
       "\\item '317'\n",
       "\\item '320'\n",
       "\\item '321'\n",
       "\\item '326'\n",
       "\\item '327'\n",
       "\\item '332'\n",
       "\\item '333'\n",
       "\\item '339'\n",
       "\\item '343'\n",
       "\\item '350'\n",
       "\\item '351'\n",
       "\\item '355'\n",
       "\\item '357'\n",
       "\\item '363'\n",
       "\\item '367'\n",
       "\\item '379'\n",
       "\\item '380'\n",
       "\\item '381'\n",
       "\\item '385'\n",
       "\\item '386'\n",
       "\\item '387'\n",
       "\\item '392'\n",
       "\\item '393'\n",
       "\\item '395'\n",
       "\\item '399'\n",
       "\\item '403'\n",
       "\\item '409'\n",
       "\\item '410'\n",
       "\\item '419'\n",
       "\\item '423'\n",
       "\\item '425'\n",
       "\\item '426'\n",
       "\\item '429'\n",
       "\\item '433'\n",
       "\\item '440'\n",
       "\\item '444'\n",
       "\\item '449'\n",
       "\\item '452'\n",
       "\\item '453'\n",
       "\\item '458'\n",
       "\\item '461'\n",
       "\\item '462'\n",
       "\\item '469'\n",
       "\\item '474'\n",
       "\\item '475'\n",
       "\\item '479'\n",
       "\\item '480'\n",
       "\\item '486'\n",
       "\\item '492'\n",
       "\\item '497'\n",
       "\\item '501'\n",
       "\\item '504'\n",
       "\\item '505'\n",
       "\\item '507'\n",
       "\\item '512'\n",
       "\\item '527'\n",
       "\\item '534'\n",
       "\\item '535'\n",
       "\\item '552'\n",
       "\\item '554'\n",
       "\\item '560'\n",
       "\\item '561'\n",
       "\\item '574'\n",
       "\\item '580'\n",
       "\\item '586'\n",
       "\\item '589'\n",
       "\\item '593'\n",
       "\\item '604'\n",
       "\\item '606'\n",
       "\\item '617'\n",
       "\\item '630'\n",
       "\\item '635'\n",
       "\\item '638'\n",
       "\\item '641'\n",
       "\\item '650'\n",
       "\\item '654'\n",
       "\\item '656'\n",
       "\\item '673'\n",
       "\\item '678'\n",
       "\\item '687'\n",
       "\\item '688'\n",
       "\\item '693'\n",
       "\\item '694'\n",
       "\\item '700'\n",
       "\\item '706'\n",
       "\\item '727'\n",
       "\\item '728'\n",
       "\\item '740'\n",
       "\\item '742'\n",
       "\\item '747'\n",
       "\\item '751'\n",
       "\\item '753'\n",
       "\\item '763'\n",
       "\\item '770'\n",
       "\\item '774'\n",
       "\\item '780'\n",
       "\\item '787'\n",
       "\\item '795'\n",
       "\\item '798'\n",
       "\\item '807'\n",
       "\\item '818'\n",
       "\\item '830'\n",
       "\\item '831'\n",
       "\\item '837'\n",
       "\\item '839'\n",
       "\\item '848'\n",
       "\\item '850'\n",
       "\\item '853'\n",
       "\\item '866'\n",
       "\\item '883'\n",
       "\\item '884'\n",
       "\\item '889'\n",
       "\\item '891'\n",
       "\\item '909'\n",
       "\\item '910'\n",
       "\\item '915'\n",
       "\\item '917'\n",
       "\\item '931'\n",
       "\\item '935'\n",
       "\\item '941'\n",
       "\\item '943'\n",
       "\\item '951'\n",
       "\\item '955'\n",
       "\\item '966'\n",
       "\\item '968'\n",
       "\\item '974'\n",
       "\\item '984'\n",
       "\\item '990'\n",
       "\\item '992'\n",
       "\\item '998'\n",
       "\\item '1003'\n",
       "\\item '1012'\n",
       "\\item '1014'\n",
       "\\item '1022'\n",
       "\\item '1038'\n",
       "\\item '1040'\n",
       "\\item '1042'\n",
       "\\item '1046'\n",
       "\\item '1051'\n",
       "\\item '1058'\n",
       "\\item '1064'\n",
       "\\item '1069'\n",
       "\\item '1070'\n",
       "\\item '1081'\n",
       "\\item '1083'\n",
       "\\item '1101'\n",
       "\\item '1111'\n",
       "\\item '1115'\n",
       "\\item '1131'\n",
       "\\item '1134'\n",
       "\\item '1144'\n",
       "\\item '1163'\n",
       "\\item '1164'\n",
       "\\item '1187'\n",
       "\\item '1191'\n",
       "\\item '1203'\n",
       "\\item '1207'\n",
       "\\item '1227'\n",
       "\\item '1230'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '2'\n",
       "2. '3'\n",
       "3. '7'\n",
       "4. '10'\n",
       "5. '19'\n",
       "6. '20'\n",
       "7. '25'\n",
       "8. '26'\n",
       "9. '28'\n",
       "10. '30'\n",
       "11. '31'\n",
       "12. '40'\n",
       "13. '46'\n",
       "14. '49'\n",
       "15. '51'\n",
       "16. '56'\n",
       "17. '57'\n",
       "18. '58'\n",
       "19. '62'\n",
       "20. '67'\n",
       "21. '77'\n",
       "22. '79'\n",
       "23. '81'\n",
       "24. '85'\n",
       "25. '87'\n",
       "26. '88'\n",
       "27. '94'\n",
       "28. '99'\n",
       "29. '104'\n",
       "30. '105'\n",
       "31. '107'\n",
       "32. '109'\n",
       "33. '111'\n",
       "34. '116'\n",
       "35. '124'\n",
       "36. '125'\n",
       "37. '126'\n",
       "38. '134'\n",
       "39. '135'\n",
       "40. '136'\n",
       "41. '141'\n",
       "42. '147'\n",
       "43. '151'\n",
       "44. '154'\n",
       "45. '155'\n",
       "46. '158'\n",
       "47. '159'\n",
       "48. '164'\n",
       "49. '169'\n",
       "50. '171'\n",
       "51. '190'\n",
       "52. '195'\n",
       "53. '197'\n",
       "54. '198'\n",
       "55. '199'\n",
       "56. '200'\n",
       "57. '203'\n",
       "58. '206'\n",
       "59. '212'\n",
       "60. '214'\n",
       "61. '216'\n",
       "62. '222'\n",
       "63. '224'\n",
       "64. '229'\n",
       "65. '233'\n",
       "66. '236'\n",
       "67. '241'\n",
       "68. '243'\n",
       "69. '245'\n",
       "70. '253'\n",
       "71. '255'\n",
       "72. '257'\n",
       "73. '260'\n",
       "74. '267'\n",
       "75. '273'\n",
       "76. '275'\n",
       "77. '276'\n",
       "78. '282'\n",
       "79. '287'\n",
       "80. '290'\n",
       "81. '291'\n",
       "82. '296'\n",
       "83. '301'\n",
       "84. '302'\n",
       "85. '303'\n",
       "86. '317'\n",
       "87. '320'\n",
       "88. '321'\n",
       "89. '326'\n",
       "90. '327'\n",
       "91. '332'\n",
       "92. '333'\n",
       "93. '339'\n",
       "94. '343'\n",
       "95. '350'\n",
       "96. '351'\n",
       "97. '355'\n",
       "98. '357'\n",
       "99. '363'\n",
       "100. '367'\n",
       "101. '379'\n",
       "102. '380'\n",
       "103. '381'\n",
       "104. '385'\n",
       "105. '386'\n",
       "106. '387'\n",
       "107. '392'\n",
       "108. '393'\n",
       "109. '395'\n",
       "110. '399'\n",
       "111. '403'\n",
       "112. '409'\n",
       "113. '410'\n",
       "114. '419'\n",
       "115. '423'\n",
       "116. '425'\n",
       "117. '426'\n",
       "118. '429'\n",
       "119. '433'\n",
       "120. '440'\n",
       "121. '444'\n",
       "122. '449'\n",
       "123. '452'\n",
       "124. '453'\n",
       "125. '458'\n",
       "126. '461'\n",
       "127. '462'\n",
       "128. '469'\n",
       "129. '474'\n",
       "130. '475'\n",
       "131. '479'\n",
       "132. '480'\n",
       "133. '486'\n",
       "134. '492'\n",
       "135. '497'\n",
       "136. '501'\n",
       "137. '504'\n",
       "138. '505'\n",
       "139. '507'\n",
       "140. '512'\n",
       "141. '527'\n",
       "142. '534'\n",
       "143. '535'\n",
       "144. '552'\n",
       "145. '554'\n",
       "146. '560'\n",
       "147. '561'\n",
       "148. '574'\n",
       "149. '580'\n",
       "150. '586'\n",
       "151. '589'\n",
       "152. '593'\n",
       "153. '604'\n",
       "154. '606'\n",
       "155. '617'\n",
       "156. '630'\n",
       "157. '635'\n",
       "158. '638'\n",
       "159. '641'\n",
       "160. '650'\n",
       "161. '654'\n",
       "162. '656'\n",
       "163. '673'\n",
       "164. '678'\n",
       "165. '687'\n",
       "166. '688'\n",
       "167. '693'\n",
       "168. '694'\n",
       "169. '700'\n",
       "170. '706'\n",
       "171. '727'\n",
       "172. '728'\n",
       "173. '740'\n",
       "174. '742'\n",
       "175. '747'\n",
       "176. '751'\n",
       "177. '753'\n",
       "178. '763'\n",
       "179. '770'\n",
       "180. '774'\n",
       "181. '780'\n",
       "182. '787'\n",
       "183. '795'\n",
       "184. '798'\n",
       "185. '807'\n",
       "186. '818'\n",
       "187. '830'\n",
       "188. '831'\n",
       "189. '837'\n",
       "190. '839'\n",
       "191. '848'\n",
       "192. '850'\n",
       "193. '853'\n",
       "194. '866'\n",
       "195. '883'\n",
       "196. '884'\n",
       "197. '889'\n",
       "198. '891'\n",
       "199. '909'\n",
       "200. '910'\n",
       "201. '915'\n",
       "202. '917'\n",
       "203. '931'\n",
       "204. '935'\n",
       "205. '941'\n",
       "206. '943'\n",
       "207. '951'\n",
       "208. '955'\n",
       "209. '966'\n",
       "210. '968'\n",
       "211. '974'\n",
       "212. '984'\n",
       "213. '990'\n",
       "214. '992'\n",
       "215. '998'\n",
       "216. '1003'\n",
       "217. '1012'\n",
       "218. '1014'\n",
       "219. '1022'\n",
       "220. '1038'\n",
       "221. '1040'\n",
       "222. '1042'\n",
       "223. '1046'\n",
       "224. '1051'\n",
       "225. '1058'\n",
       "226. '1064'\n",
       "227. '1069'\n",
       "228. '1070'\n",
       "229. '1081'\n",
       "230. '1083'\n",
       "231. '1101'\n",
       "232. '1111'\n",
       "233. '1115'\n",
       "234. '1131'\n",
       "235. '1134'\n",
       "236. '1144'\n",
       "237. '1163'\n",
       "238. '1164'\n",
       "239. '1187'\n",
       "240. '1191'\n",
       "241. '1203'\n",
       "242. '1207'\n",
       "243. '1227'\n",
       "244. '1230'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"2\"    \"3\"    \"7\"    \"10\"   \"19\"   \"20\"   \"25\"   \"26\"   \"28\"   \"30\"  \n",
       " [11] \"31\"   \"40\"   \"46\"   \"49\"   \"51\"   \"56\"   \"57\"   \"58\"   \"62\"   \"67\"  \n",
       " [21] \"77\"   \"79\"   \"81\"   \"85\"   \"87\"   \"88\"   \"94\"   \"99\"   \"104\"  \"105\" \n",
       " [31] \"107\"  \"109\"  \"111\"  \"116\"  \"124\"  \"125\"  \"126\"  \"134\"  \"135\"  \"136\" \n",
       " [41] \"141\"  \"147\"  \"151\"  \"154\"  \"155\"  \"158\"  \"159\"  \"164\"  \"169\"  \"171\" \n",
       " [51] \"190\"  \"195\"  \"197\"  \"198\"  \"199\"  \"200\"  \"203\"  \"206\"  \"212\"  \"214\" \n",
       " [61] \"216\"  \"222\"  \"224\"  \"229\"  \"233\"  \"236\"  \"241\"  \"243\"  \"245\"  \"253\" \n",
       " [71] \"255\"  \"257\"  \"260\"  \"267\"  \"273\"  \"275\"  \"276\"  \"282\"  \"287\"  \"290\" \n",
       " [81] \"291\"  \"296\"  \"301\"  \"302\"  \"303\"  \"317\"  \"320\"  \"321\"  \"326\"  \"327\" \n",
       " [91] \"332\"  \"333\"  \"339\"  \"343\"  \"350\"  \"351\"  \"355\"  \"357\"  \"363\"  \"367\" \n",
       "[101] \"379\"  \"380\"  \"381\"  \"385\"  \"386\"  \"387\"  \"392\"  \"393\"  \"395\"  \"399\" \n",
       "[111] \"403\"  \"409\"  \"410\"  \"419\"  \"423\"  \"425\"  \"426\"  \"429\"  \"433\"  \"440\" \n",
       "[121] \"444\"  \"449\"  \"452\"  \"453\"  \"458\"  \"461\"  \"462\"  \"469\"  \"474\"  \"475\" \n",
       "[131] \"479\"  \"480\"  \"486\"  \"492\"  \"497\"  \"501\"  \"504\"  \"505\"  \"507\"  \"512\" \n",
       "[141] \"527\"  \"534\"  \"535\"  \"552\"  \"554\"  \"560\"  \"561\"  \"574\"  \"580\"  \"586\" \n",
       "[151] \"589\"  \"593\"  \"604\"  \"606\"  \"617\"  \"630\"  \"635\"  \"638\"  \"641\"  \"650\" \n",
       "[161] \"654\"  \"656\"  \"673\"  \"678\"  \"687\"  \"688\"  \"693\"  \"694\"  \"700\"  \"706\" \n",
       "[171] \"727\"  \"728\"  \"740\"  \"742\"  \"747\"  \"751\"  \"753\"  \"763\"  \"770\"  \"774\" \n",
       "[181] \"780\"  \"787\"  \"795\"  \"798\"  \"807\"  \"818\"  \"830\"  \"831\"  \"837\"  \"839\" \n",
       "[191] \"848\"  \"850\"  \"853\"  \"866\"  \"883\"  \"884\"  \"889\"  \"891\"  \"909\"  \"910\" \n",
       "[201] \"915\"  \"917\"  \"931\"  \"935\"  \"941\"  \"943\"  \"951\"  \"955\"  \"966\"  \"968\" \n",
       "[211] \"974\"  \"984\"  \"990\"  \"992\"  \"998\"  \"1003\" \"1012\" \"1014\" \"1022\" \"1038\"\n",
       "[221] \"1040\" \"1042\" \"1046\" \"1051\" \"1058\" \"1064\" \"1069\" \"1070\" \"1081\" \"1083\"\n",
       "[231] \"1101\" \"1111\" \"1115\" \"1131\" \"1134\" \"1144\" \"1163\" \"1164\" \"1187\" \"1191\"\n",
       "[241] \"1203\" \"1207\" \"1227\" \"1230\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of team/year pairs where no. of playoff teams is 8: 128"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  2   4   8  10 \n",
       " 14  92 128  10 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseballP$NumComp <- as.integer(table(baseballP$Year)[as.character(baseballP$Year)])\n",
    "str(baseballP)\n",
    "rownames(baseballP)\n",
    "\n",
    "# get number of team/year pairs where no. of playoff teams=8\n",
    "cat(sprintf(\"\\nNo. of team/year pairs where no. of playoff teams is 8: %s\",\n",
    "            NROW(subset(baseballP, baseballP$NumComp == 8))))\n",
    "\n",
    "# OR...\n",
    "table(baseballP$NumComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1C (checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. of losing teams total (subset): 197"
     ]
    },
    {
     "data": {
      "text/html": [
       "47"
      ],
      "text/latex": [
       "47"
      ],
      "text/markdown": [
       "47"
      ],
      "text/plain": [
       "[1] 47"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseballP$WorldSeries <- ifelse(baseballP$RankPlayoffs == 1, 1, 0)\n",
    "cat(sprintf(\"\\nNo. of losing teams total (subset): %s\",\n",
    "            length(baseballP$WorldSeries[baseballP$WorldSeries == 0])))\n",
    "\n",
    "# baseballP\n",
    "NROW(subset(baseballP, baseballP$WorldSeries == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1D (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: algorithm did not converge\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>name</th><th scope=col>variable</th><th scope=col>intercept</th><th scope=col>varP</th><th scope=col>intP</th><th scope=col>aic</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>League       </td><td> -0.158292579</td><td> -1.3558352  </td><td>0.6264465507 </td><td>1.495819e-09 </td><td>242.8846     </td></tr>\n",
       "\t<tr><td>Year         </td><td> -0.036999890</td><td> 72.2360208  </td><td>0.0011544695 </td><td>1.422431e-03 </td><td>232.3508     </td></tr>\n",
       "\t<tr><td>RS           </td><td> -0.002681168</td><td>  0.6612262  </td><td>0.2013364471 </td><td>6.861757e-01 </td><td>241.4543     </td></tr>\n",
       "\t<tr><td>RA           </td><td> -0.005053397</td><td>  1.8881745  </td><td>0.0262137758 </td><td>2.031958e-01 </td><td>237.8839     </td></tr>\n",
       "\t<tr><td>W            </td><td>  0.056714483</td><td> -6.8556774  </td><td>0.0577260348 </td><td>1.714458e-02 </td><td>239.5105     </td></tr>\n",
       "\t<tr><td>OBP          </td><td>-12.401837341</td><td>  2.7413679  </td><td>0.2959201177 </td><td>4.918963e-01 </td><td>242.0209     </td></tr>\n",
       "\t<tr><td>SLG          </td><td>-11.129812981</td><td>  3.1997590  </td><td>0.0504256593 </td><td>1.748288e-01 </td><td>239.2283     </td></tr>\n",
       "\t<tr><td>BA           </td><td> -2.976491008</td><td> -0.6392427  </td><td>0.8385900817 </td><td>8.697621e-01 </td><td>243.0804     </td></tr>\n",
       "\t<tr><td>RankSeason   </td><td> -0.206926332</td><td> -0.8256129  </td><td>0.0438313556 </td><td>1.151641e-02 </td><td>238.7546     </td></tr>\n",
       "\t<tr><td>RankPlayoffs </td><td>-47.682457516</td><td> 71.7719409  </td><td>0.9980079493 </td><td>9.982285e-01 </td><td>  4.0000     </td></tr>\n",
       "\t<tr><td>Games        </td><td>  0.171690765</td><td>-29.2414027  </td><td>0.5220175769 </td><td>5.008564e-01 </td><td>242.6988     </td></tr>\n",
       "\t<tr><td>NumComp      </td><td> -0.252196729</td><td>  0.0386751  </td><td>0.0006784323 </td><td>9.295592e-01 </td><td>230.9592     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " name & variable & intercept & varP & intP & aic\\\\\n",
       "\\hline\n",
       "\t League        &  -0.158292579 &  -1.3558352   & 0.6264465507  & 1.495819e-09  & 242.8846     \\\\\n",
       "\t Year          &  -0.036999890 &  72.2360208   & 0.0011544695  & 1.422431e-03  & 232.3508     \\\\\n",
       "\t RS            &  -0.002681168 &   0.6612262   & 0.2013364471  & 6.861757e-01  & 241.4543     \\\\\n",
       "\t RA            &  -0.005053397 &   1.8881745   & 0.0262137758  & 2.031958e-01  & 237.8839     \\\\\n",
       "\t W             &   0.056714483 &  -6.8556774   & 0.0577260348  & 1.714458e-02  & 239.5105     \\\\\n",
       "\t OBP           & -12.401837341 &   2.7413679   & 0.2959201177  & 4.918963e-01  & 242.0209     \\\\\n",
       "\t SLG           & -11.129812981 &   3.1997590   & 0.0504256593  & 1.748288e-01  & 239.2283     \\\\\n",
       "\t BA            &  -2.976491008 &  -0.6392427   & 0.8385900817  & 8.697621e-01  & 243.0804     \\\\\n",
       "\t RankSeason    &  -0.206926332 &  -0.8256129   & 0.0438313556  & 1.151641e-02  & 238.7546     \\\\\n",
       "\t RankPlayoffs  & -47.682457516 &  71.7719409   & 0.9980079493  & 9.982285e-01  &   4.0000     \\\\\n",
       "\t Games         &   0.171690765 & -29.2414027   & 0.5220175769  & 5.008564e-01  & 242.6988     \\\\\n",
       "\t NumComp       &  -0.252196729 &   0.0386751   & 0.0006784323  & 9.295592e-01  & 230.9592     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "name | variable | intercept | varP | intP | aic | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| League        |  -0.158292579 |  -1.3558352   | 0.6264465507  | 1.495819e-09  | 242.8846      | \n",
       "| Year          |  -0.036999890 |  72.2360208   | 0.0011544695  | 1.422431e-03  | 232.3508      | \n",
       "| RS            |  -0.002681168 |   0.6612262   | 0.2013364471  | 6.861757e-01  | 241.4543      | \n",
       "| RA            |  -0.005053397 |   1.8881745   | 0.0262137758  | 2.031958e-01  | 237.8839      | \n",
       "| W             |   0.056714483 |  -6.8556774   | 0.0577260348  | 1.714458e-02  | 239.5105      | \n",
       "| OBP           | -12.401837341 |   2.7413679   | 0.2959201177  | 4.918963e-01  | 242.0209      | \n",
       "| SLG           | -11.129812981 |   3.1997590   | 0.0504256593  | 1.748288e-01  | 239.2283      | \n",
       "| BA            |  -2.976491008 |  -0.6392427   | 0.8385900817  | 8.697621e-01  | 243.0804      | \n",
       "| RankSeason    |  -0.206926332 |  -0.8256129   | 0.0438313556  | 1.151641e-02  | 238.7546      | \n",
       "| RankPlayoffs  | -47.682457516 |  71.7719409   | 0.9980079493  | 9.982285e-01  |   4.0000      | \n",
       "| Games         |   0.171690765 | -29.2414027   | 0.5220175769  | 5.008564e-01  | 242.6988      | \n",
       "| NumComp       |  -0.252196729 |   0.0386751   | 0.0006784323  | 9.295592e-01  | 230.9592      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   name         variable      intercept   varP         intP         aic     \n",
       "1  League        -0.158292579  -1.3558352 0.6264465507 1.495819e-09 242.8846\n",
       "2  Year          -0.036999890  72.2360208 0.0011544695 1.422431e-03 232.3508\n",
       "3  RS            -0.002681168   0.6612262 0.2013364471 6.861757e-01 241.4543\n",
       "4  RA            -0.005053397   1.8881745 0.0262137758 2.031958e-01 237.8839\n",
       "5  W              0.056714483  -6.8556774 0.0577260348 1.714458e-02 239.5105\n",
       "6  OBP          -12.401837341   2.7413679 0.2959201177 4.918963e-01 242.0209\n",
       "7  SLG          -11.129812981   3.1997590 0.0504256593 1.748288e-01 239.2283\n",
       "8  BA            -2.976491008  -0.6392427 0.8385900817 8.697621e-01 243.0804\n",
       "9  RankSeason    -0.206926332  -0.8256129 0.0438313556 1.151641e-02 238.7546\n",
       "10 RankPlayoffs -47.682457516  71.7719409 0.9980079493 9.982285e-01   4.0000\n",
       "11 Games          0.171690765 -29.2414027 0.5220175769 5.008564e-01 242.6988\n",
       "12 NumComp       -0.252196729   0.0386751 0.0006784323 9.295592e-01 230.9592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = baseballP$WorldSeries ~ baseballP[[\"Year\"]], family = \"binomial\")\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.0297  -0.6797  -0.5435  -0.4648   2.1504  \n",
       "\n",
       "Coefficients:\n",
       "                    Estimate Std. Error z value Pr(>|z|)   \n",
       "(Intercept)         72.23602   22.64409    3.19  0.00142 **\n",
       "baseballP[[\"Year\"]] -0.03700    0.01138   -3.25  0.00115 **\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 239.12  on 243  degrees of freedom\n",
       "Residual deviance: 228.35  on 242  degrees of freedom\n",
       "AIC: 232.35\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAHgCAMAAACo6b1DAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nCRAgSIAAQQIECBIgQJAAAYIECPwBejxcnEhOIyAAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results <- data.frame(name=character(),\n",
    "                      variable=double(),\n",
    "                      intercept=double(),\n",
    "                      varP=double(),\n",
    "                      intP=double(),\n",
    "                      aic=double(),\n",
    "                      stringsAsFactors=FALSE)\n",
    "\n",
    "\n",
    "# for each predictor, generate single regression model and append model statistics to \"results\"\n",
    "for (var in colnames(baseballP)) {\n",
    "    if (var %in% c(\"League\", \"Year\", \"RS\", \"RA\", \"W\", \"OBP\", \"SLG\", \"BA\", \"NumComp\", \"RankSeason\", \"RankPlayoffs\", \"Games\")) {\n",
    "        model1D <- glm(baseballP$WorldSeries~baseballP[[var]], family=\"binomial\")\n",
    "#         plot(baseballP[[var]],baseballP$WorldSeries, xlab=var)\n",
    "#         curve(exp(coefficients(model1D)[1]+coefficients(model1D)[2]*x)/\n",
    "#               (1+exp(coefficients(model1D)[1]+coefficients(model1D)[2]*x)), add=T)\n",
    "#         print(var)\n",
    "#         print(summary(model1D))\n",
    "        model_stats <- data.frame(name = var,\n",
    "                                  variable = coefficients(model1D)[[2]],\n",
    "                                  intercept = coefficients(model1D)[[1]],\n",
    "                                  varP = coef(summary(model1D))[2,4],\n",
    "                                  intP = coef(summary(model1D))[1,4],\n",
    "                                  aic = summary(model1D)$aic)\n",
    "        results <- rbind(results, model_stats)\n",
    "}}\n",
    "\n",
    "# transform column datatype to numeric\n",
    "# for (i in colnames(results)[2:5]) {\n",
    "#   results[[i]] <- as.numeric(results[[i]])}\n",
    "\n",
    "# display results\n",
    "results\n",
    "model1D <- glm(baseballP$WorldSeries~baseballP[[\"Year\"]], family=\"binomial\")\n",
    "plot(baseballP[[\"Year\"]],baseballP$WorldSeries)\n",
    "abline(model1D)\n",
    "summary(model1D)\n",
    "\n",
    "# we can observe that variables \"Year\", \"RA\", \"NumComp\", \"RankSeason\" are significant predictors\n",
    "# near-hits include \"W\", \"SLG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1E (c)\n",
    "\n",
    "There are three significant predictor variable as found in part 1D, i.e. **Year**, **RA** and **NumComp** and **RankSeason**. However, running a multiple regression on all three does not give us significant predictors, in fact, all three of them turn non-significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = WorldSeries ~ Year + RA + NumComp + RankSeason, \n",
       "    family = \"binomial\", data = baseballP)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.0336  -0.7689  -0.5139  -0.4583   2.2195  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept) 12.5874376 53.6474210   0.235    0.814\n",
       "Year        -0.0061425  0.0274665  -0.224    0.823\n",
       "RA          -0.0008238  0.0027391  -0.301    0.764\n",
       "NumComp     -0.1794264  0.1815933  -0.988    0.323\n",
       "RankSeason  -0.0685046  0.1203459  -0.569    0.569\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 239.12  on 243  degrees of freedom\n",
       "Residual deviance: 226.37  on 239  degrees of freedom\n",
       "AIC: 236.37\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1E <- glm(WorldSeries~Year+RA+NumComp+RankSeason, data=baseballP, family=\"binomial\")\n",
    "summary(model1E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1F (c)\n",
    "\n",
    "Yes there is one. The variables **Year** is highly correlated with **NumComp** by $0.914$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Year</th><th scope=col>RA</th><th scope=col>NumComp</th><th scope=col>RankSeason</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Year</th><td>1.0000000</td><td>0.4762422</td><td>0.9139548</td><td>0.3852191</td></tr>\n",
       "\t<tr><th scope=row>RA</th><td>0.4762422</td><td>1.0000000</td><td>0.5136769</td><td>0.3991413</td></tr>\n",
       "\t<tr><th scope=row>NumComp</th><td>0.9139548</td><td>0.5136769</td><td>1.0000000</td><td>0.4247393</td></tr>\n",
       "\t<tr><th scope=row>RankSeason</th><td>0.3852191</td><td>0.3991413</td><td>0.4247393</td><td>1.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Year & RA & NumComp & RankSeason\\\\\n",
       "\\hline\n",
       "\tYear & 1.0000000 & 0.4762422 & 0.9139548 & 0.3852191\\\\\n",
       "\tRA & 0.4762422 & 1.0000000 & 0.5136769 & 0.3991413\\\\\n",
       "\tNumComp & 0.9139548 & 0.5136769 & 1.0000000 & 0.4247393\\\\\n",
       "\tRankSeason & 0.3852191 & 0.3991413 & 0.4247393 & 1.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Year | RA | NumComp | RankSeason | \n",
       "|---|---|---|---|\n",
       "| Year | 1.0000000 | 0.4762422 | 0.9139548 | 0.3852191 | \n",
       "| RA | 0.4762422 | 1.0000000 | 0.5136769 | 0.3991413 | \n",
       "| NumComp | 0.9139548 | 0.5136769 | 1.0000000 | 0.4247393 | \n",
       "| RankSeason | 0.3852191 | 0.3991413 | 0.4247393 | 1.0000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "           Year      RA        NumComp   RankSeason\n",
       "Year       1.0000000 0.4762422 0.9139548 0.3852191 \n",
       "RA         0.4762422 1.0000000 0.5136769 0.3991413 \n",
       "NumComp    0.9139548 0.5136769 1.0000000 0.4247393 \n",
       "RankSeason 0.3852191 0.3991413 0.4247393 1.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAHgCAMAAACo6b1DAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAHgCAMAAACo6b1DAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAHgCAMAAACo6b1DAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nPJAltqBXAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(baseballP[,c(\"Year\", \"RA\", \"NumComp\", \"RankSeason\")])\n",
    "\n",
    "plot(baseballP$Year, baseballP$RA)\n",
    "plot(baseballP$Year, baseballP$NumComp)\n",
    "plot(baseballP$RA, baseballP$NumComp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1G (c)\n",
    "\n",
    "Smallest AIC of 230.9592 belongs to model with **WorldSeries~NumComp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "233.876587091113"
      ],
      "text/latex": [
       "233.876587091113"
      ],
      "text/markdown": [
       "233.876587091113"
      ],
      "text/plain": [
       "[1] 233.8766"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "233.5524479584"
      ],
      "text/latex": [
       "233.5524479584"
      ],
      "text/markdown": [
       "233.5524479584"
      ],
      "text/plain": [
       "[1] 233.5524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "232.897168212545"
      ],
      "text/latex": [
       "232.897168212545"
      ],
      "text/markdown": [
       "232.897168212545"
      ],
      "text/plain": [
       "[1] 232.8972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "238.217989366883"
      ],
      "text/latex": [
       "238.217989366883"
      ],
      "text/markdown": [
       "238.217989366883"
      ],
      "text/plain": [
       "[1] 238.218"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "232.742945386299"
      ],
      "text/latex": [
       "232.742945386299"
      ],
      "text/markdown": [
       "232.742945386299"
      ],
      "text/plain": [
       "[1] 232.7429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "232.523952903188"
      ],
      "text/latex": [
       "232.523952903188"
      ],
      "text/markdown": [
       "232.523952903188"
      ],
      "text/plain": [
       "[1] 232.524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1GA <- glm(WorldSeries~Year+RA, data=baseballP, family=\"binomial\")\n",
    "model1GB <- glm(WorldSeries~Year+RankSeason, data=baseballP, family=\"binomial\")\n",
    "model1GC <- glm(WorldSeries~Year+NumComp, data=baseballP, family=\"binomial\")\n",
    "model1GD <- glm(WorldSeries~RA+RankSeason, data=baseballP, family=\"binomial\")\n",
    "model1GE <- glm(WorldSeries~RA+NumComp, data=baseballP, family=\"binomial\")\n",
    "model1GF <- glm(WorldSeries~RankSeason+NumComp, data=baseballP, family=\"binomial\")\n",
    "\n",
    "summary(model1GA)$aic\n",
    "summary(model1GB)$aic\n",
    "summary(model1GC)$aic\n",
    "summary(model1GD)$aic\n",
    "summary(model1GE)$aic\n",
    "summary(model1GF)$aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1H\n",
    "\n",
    "Overall it seems the winning of playoffs has a large reliance on unmodelled variables (which we can refer to as luck or environmental factors) than other season performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question deux\n",
    "\n",
    "### Part 2A (c)\n",
    "There are a total of 675 parolees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t675 obs. of  9 variables:\n",
      " $ Male            : int  1 0 1 1 1 1 1 0 0 1 ...\n",
      " $ RaceWhite       : int  1 1 0 1 0 0 1 1 1 0 ...\n",
      " $ Age             : num  33.2 39.7 29.5 22.4 21.6 46.7 31 24.6 32.6 29.1 ...\n",
      " $ State           : Factor w/ 4 levels \"Kentucky\",\"Louisiana\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " $ TimeServed      : num  5.5 5.4 5.6 5.7 5.4 6 6 4.8 4.5 4.7 ...\n",
      " $ MaxSentence     : int  18 12 12 18 12 18 18 12 13 12 ...\n",
      " $ MultipleOffenses: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ Crime           : Factor w/ 4 levels \"Driving\",\"Drugs\",..: 1 2 2 4 4 1 2 4 2 3 ...\n",
      " $ Violator        : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "parole <- read.csv(\"csv/Parole.csv\")\n",
    "str(parole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2B (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "78"
      ],
      "text/latex": [
       "78"
      ],
      "text/markdown": [
       "78"
      ],
      "text/plain": [
       "[1] 78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(parole$Violator[parole$Violator == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2C (c)\n",
    "\n",
    "Both **State** and **Crime** are unordered factors with at least 3 levels (they have 4 levels each)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2D (c)\n",
    "\n",
    "Roughly $70\\%$ of parolees are allocated to the training set whilst the other $30\\%$ go to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "473"
      ],
      "text/latex": [
       "473"
      ],
      "text/markdown": [
       "473"
      ],
      "text/plain": [
       "[1] 473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "202"
      ],
      "text/latex": [
       "202"
      ],
      "text/markdown": [
       "202"
      ],
      "text/plain": [
       "[1] 202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(144)\n",
    "library(caTools)\n",
    "split <- sample.split(parole$Violator, SplitRatio=0.7)\n",
    "parole_train <- subset(parole, split==T)\n",
    "parole_test <- subset(parole, split==F)\n",
    "\n",
    "NROW(parole_train)\n",
    "NROW(parole_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2E (c)\n",
    "\n",
    "The only significant variables are **RaceWhite**, **StateVirginia** and **MultipleOffenses**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Violator ~ ., family = binomial, data = parole_train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.7041  -0.4236  -0.2719  -0.1690   2.8375  \n",
       "\n",
       "Coefficients:\n",
       "                   Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)      -2.0361809  1.4474831  -1.407   0.1595    \n",
       "Male              0.3869904  0.4379613   0.884   0.3769    \n",
       "RaceWhite        -0.8867192  0.3950660  -2.244   0.0248 *  \n",
       "Age              -0.0001756  0.0160852  -0.011   0.9913    \n",
       "StateLouisiana    0.3916790  0.5719679   0.685   0.4935    \n",
       "StateOther       -0.4433007  0.4816619  -0.920   0.3574    \n",
       "StateVirginia    -3.8400884  0.6904894  -5.561 2.68e-08 ***\n",
       "TimeServed       -0.1238867  0.1204230  -1.029   0.3036    \n",
       "MaxSentence       0.0802954  0.0553747   1.450   0.1470    \n",
       "MultipleOffenses  1.6119919  0.3853050   4.184 2.87e-05 ***\n",
       "CrimeDrugs       -0.2663428  0.6412857  -0.415   0.6779    \n",
       "CrimeLarceny      0.6954770  0.6714835   1.036   0.3003    \n",
       "CrimeOther        0.0117627  0.5713035   0.021   0.9836    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 340.04  on 472  degrees of freedom\n",
       "Residual deviance: 251.48  on 460  degrees of freedom\n",
       "AIC: 277.48\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2E <- glm(Violator~., data=parole_train, family=binomial)\n",
    "summary(model2E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2F (c)\n",
    "\n",
    "Our model predicts that a parolee who committed multiple offenses has $5.01$ times higher odds of being a violator than a parolee who did not commit multiple offenses but is otherwise identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>0.130526251755564</dd>\n",
       "\t<dt>Male</dt>\n",
       "\t\t<dd>1.47254235803815</dd>\n",
       "\t<dt>RaceWhite</dt>\n",
       "\t\t<dd>0.41200522771062</dd>\n",
       "\t<dt>Age</dt>\n",
       "\t\t<dd>0.99982439986818</dd>\n",
       "\t<dt>StateLouisiana</dt>\n",
       "\t\t<dd>1.47946273129565</dd>\n",
       "\t<dt>StateOther</dt>\n",
       "\t\t<dd>0.641914185641291</dd>\n",
       "\t<dt>StateVirginia</dt>\n",
       "\t\t<dd>0.0214917010775244</dd>\n",
       "\t<dt>TimeServed</dt>\n",
       "\t\t<dd>0.883479931092115</dd>\n",
       "\t<dt>MaxSentence</dt>\n",
       "\t\t<dd>1.08360709249038</dd>\n",
       "\t<dt>MultipleOffenses</dt>\n",
       "\t\t<dd>5.01278605570312</dd>\n",
       "\t<dt>CrimeDrugs</dt>\n",
       "\t\t<dd>0.766176459636451</dd>\n",
       "\t<dt>CrimeLarceny</dt>\n",
       "\t\t<dd>2.00466500542348</dd>\n",
       "\t<dt>CrimeOther</dt>\n",
       "\t\t<dd>1.01183210409731</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 0.130526251755564\n",
       "\\item[Male] 1.47254235803815\n",
       "\\item[RaceWhite] 0.41200522771062\n",
       "\\item[Age] 0.99982439986818\n",
       "\\item[StateLouisiana] 1.47946273129565\n",
       "\\item[StateOther] 0.641914185641291\n",
       "\\item[StateVirginia] 0.0214917010775244\n",
       "\\item[TimeServed] 0.883479931092115\n",
       "\\item[MaxSentence] 1.08360709249038\n",
       "\\item[MultipleOffenses] 5.01278605570312\n",
       "\\item[CrimeDrugs] 0.766176459636451\n",
       "\\item[CrimeLarceny] 2.00466500542348\n",
       "\\item[CrimeOther] 1.01183210409731\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   0.130526251755564Male\n",
       ":   1.47254235803815RaceWhite\n",
       ":   0.41200522771062Age\n",
       ":   0.99982439986818StateLouisiana\n",
       ":   1.47946273129565StateOther\n",
       ":   0.641914185641291StateVirginia\n",
       ":   0.0214917010775244TimeServed\n",
       ":   0.883479931092115MaxSentence\n",
       ":   1.08360709249038MultipleOffenses\n",
       ":   5.01278605570312CrimeDrugs\n",
       ":   0.766176459636451CrimeLarceny\n",
       ":   2.00466500542348CrimeOther\n",
       ":   1.01183210409731\n",
       "\n"
      ],
      "text/plain": [
       "     (Intercept)             Male        RaceWhite              Age \n",
       "       0.1305263        1.4725424        0.4120052        0.9998244 \n",
       "  StateLouisiana       StateOther    StateVirginia       TimeServed \n",
       "       1.4794627        0.6419142        0.0214917        0.8834799 \n",
       "     MaxSentence MultipleOffenses       CrimeDrugs     CrimeLarceny \n",
       "       1.0836071        5.0127861        0.7661765        2.0046650 \n",
       "      CrimeOther \n",
       "       1.0118321 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp(coef(model2E))\n",
    "\n",
    "# model2F <- glm(Violator~RaceWhite+State+MultipleOffenses, data=parole_train, family=binomial)\n",
    "# summary(model2F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2G (c)\n",
    "\n",
    "- Odds that indiviudal is a violator: $0.28441$\n",
    "- Probability that individual is a violator: $0.22143$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Odds: 0.28441263680295\n",
      "Odds: 0.28441263680295"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.221434006995513"
      ],
      "text/latex": [
       "\\textbf{1:} 0.221434006995513"
      ],
      "text/markdown": [
       "**1:** 0.221434006995513"
      ],
      "text/plain": [
       "       1 \n",
       "0.221434 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.221434006995513"
      ],
      "text/latex": [
       "\\textbf{1:} 0.221434006995513"
      ],
      "text/markdown": [
       "**1:** 0.221434006995513"
      ],
      "text/plain": [
       "       1 \n",
       "0.221434 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get odds (FIRST METHOD)\n",
    "prob2G <- predict(model2E, data.frame(Male=1,\n",
    "                            RaceWhite=1,\n",
    "                            Age=50,\n",
    "                            State=\"Kentucky\",\n",
    "                            TimeServed=3,\n",
    "                            MaxSentence=12,\n",
    "                            MultipleOffenses=0,\n",
    "                            Crime=\"Larceny\"), type=\"response\")\n",
    "cat(sprintf(\"\\nOdds: %s\", (prob2G)/(1-prob2G)))\n",
    "\n",
    "# get odds (SECOND METHOD)\n",
    "cat(sprintf(\"\\nOdds: %s\", exp(predict(model2E, data.frame(Male=1,\n",
    "                            RaceWhite=1,\n",
    "                            Age=50,\n",
    "                            State=\"Kentucky\",\n",
    "                            TimeServed=3,\n",
    "                            MaxSentence=12,\n",
    "                            MultipleOffenses=0,\n",
    "                            Crime=\"Larceny\")))))\n",
    "\n",
    "\n",
    "# get probability\n",
    "prob2G\n",
    "predict(model2E, data.frame(Male=1,\n",
    "                            RaceWhite=1,\n",
    "                            Age=50,\n",
    "                            State=\"Kentucky\",\n",
    "                            TimeServed=3,\n",
    "                            MaxSentence=12,\n",
    "                            MultipleOffenses=0,\n",
    "                            Crime=\"Larceny\"), type=\"response\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2H (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.907279069042028"
      ],
      "text/latex": [
       "0.907279069042028"
      ],
      "text/markdown": [
       "0.907279069042028"
      ],
      "text/plain": [
       "[1] 0.9072791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict2H <- predict(model2E, parole_test, type=\"response\")\n",
    "max(predict2H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2I (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE 167  11\n",
       "  TRUE   12  12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.521739130434783"
      ],
      "text/latex": [
       "0.521739130434783"
      ],
      "text/markdown": [
       "0.521739130434783"
      ],
      "text/plain": [
       "[1] 0.5217391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.932960893854749"
      ],
      "text/latex": [
       "0.932960893854749"
      ],
      "text/markdown": [
       "0.932960893854749"
      ],
      "text/plain": [
       "[1] 0.9329609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.886138613861386"
      ],
      "text/latex": [
       "0.886138613861386"
      ],
      "text/markdown": [
       "0.886138613861386"
      ],
      "text/plain": [
       "[1] 0.8861386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ROCR) # Load ROC-R package\n",
    "\n",
    "# confusion matrix\n",
    "table(predict2H>0.5, parole_test$Violator)\n",
    "\n",
    "# sensitivity (TPR)\n",
    "tpr2I <- 12/(11+12)\n",
    "tpr2I\n",
    "\n",
    "# specificity (TNR)\n",
    "tnr2I <- 167/(167+12)\n",
    "tnr2I\n",
    "\n",
    "# accuracy\n",
    "(12+167)/(167+12+11+12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2J (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE 179  23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.886138613861386"
      ],
      "text/latex": [
       "0.886138613861386"
      ],
      "text/markdown": [
       "0.886138613861386"
      ],
      "text/plain": [
       "[1] 0.8861386"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "table(predict2H>1, parole_test$Violator)\n",
    "\n",
    "# accuracy of simple model predicting every parolee is a non-violator\n",
    "tpr2J <- 0\n",
    "tnr2J <- 1\n",
    "\n",
    "accuracy <- (179)/(179+23)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2K (c)\n",
    "Since the board is 'particularly concerned' with release of parolees who will violate, the board will assign more cost to a false negative than a false positive, and should therefore use a logistic regression cutoff less than $0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2L (c) !\n",
    "\n",
    "The model is of limited value to the board because it cannot outperform a simple baseline, and using a different logistic regression cutoff is likely to improve the model's value.\n",
    "\n",
    "**Corrected answer:** The model is likely of value to the board, and using a different logistic regression cutoff is likely to improve the model's value. Whilst both simple and the logistic model have the same accuracy, the baseline model produces many more false negatives (23) as opposed to the logisitic model (11) since the board is 'particularly concerned' with release of parolees who will violate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2M (c)\n",
    "\n",
    "$AUC = 0.8946$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An object of class \"performance\"\n",
       "Slot \"x.name\":\n",
       "[1] \"None\"\n",
       "\n",
       "Slot \"y.name\":\n",
       "[1] \"Area under the ROC curve\"\n",
       "\n",
       "Slot \"alpha.name\":\n",
       "[1] \"none\"\n",
       "\n",
       "Slot \"x.values\":\n",
       "list()\n",
       "\n",
       "Slot \"y.values\":\n",
       "[[1]]\n",
       "[1] 0.8945834\n",
       "\n",
       "\n",
       "Slot \"alpha.values\":\n",
       "list()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROCRpredict2M <- prediction(predict2H, parole_test$Violator)\n",
    "ROCRperf2M <- performance(ROCRpredict2M, measure=\"auc\")\n",
    "ROCRperf2M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2N (c)\n",
    "\n",
    "The probability the model can correctly differentiate between a randomly selected parole violator and a randomly selected parole non-violator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2O (c) !!\n",
    "\n",
    "We should use the current dataset, expanded to include the missing parolees. Each added parolee should be labeled with $Violator=NA$, because the true outcome has not been observed for these individuals. (**Note**: this does not build a better model)\n",
    "\n",
    "**Corrected answer:** We should use a dataset tracking a group of parolees from the start of their parole until either they violated parole or they completed their term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question trois\n",
    "\n",
    "### Part 3A (c)\n",
    "\n",
    "`sample.split()` is used to balance the dependent variable between the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "225 525 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       " 75 175 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credit <- read.csv(\"csv/germancredit.csv\")\n",
    "\n",
    "# obtain random training/test set split\n",
    "set.seed(2016)\n",
    "library(caTools)\n",
    "spl <- sample.split(credit$resp, 0.75)\n",
    "credit_train <- subset(credit, spl==T)\n",
    "credit_test <- subset(credit, spl==F)\n",
    "\n",
    "table(credit_train$resp)\n",
    "table(credit_test$resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3B (c)\n",
    "\n",
    "Fitted model: $\\large resp=\\frac{e^{0.84730}}{1+e^{0.84730}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = resp ~ 1, family = binomial, data = credit_train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.5518  -1.5518   0.8446   0.8446   0.8446  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.84730    0.07968   10.63   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 916.3  on 749  degrees of freedom\n",
       "Residual deviance: 916.3  on 749  degrees of freedom\n",
       "AIC: 918.3\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3B <- glm(resp~1,data=credit_train, family=binomial)\n",
    "summary(model3B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3C (c)\n",
    "\n",
    "$$Good:Bad = \\frac{e^{0.84720}}{1+e^{0.84720}}$$\n",
    "\n",
    "Note that this $Good:Bad$ ratio is exactly identical to the odds ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.7"
      ],
      "text/latex": [
       "0.7"
      ],
      "text/markdown": [
       "0.7"
      ],
      "text/plain": [
       "[1] 0.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.699979448916476"
      ],
      "text/latex": [
       "0.699979448916476"
      ],
      "text/markdown": [
       "0.699979448916476"
      ],
      "text/plain": [
       "[1] 0.6999794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "good3C <- length(credit_train$resp[credit_train$resp==1])\n",
    "bad3C <- length(credit_train$resp[credit_train$resp==0])\n",
    "\n",
    "fraction3C <- good3C/(good3C+bad3C)\n",
    "fraction3C\n",
    "exp(0.84720)/(1+exp(0.84720))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3D (c)\n",
    "\n",
    "Variables **chkacct**, **dur**, **hist**, **amt**, **sav**, **instrate**, **malesingle**, **age**, **foreign** are significant at the $10\\%$ level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = resp ~ ., family = binomial, data = credit_train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.6850  -0.7577   0.4041   0.6919   1.9701  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  8.764e-01  1.028e+00   0.853 0.393872    \n",
       "chkacct      5.652e-01  8.470e-02   6.674 2.50e-11 ***\n",
       "dur         -2.053e-02  1.024e-02  -2.005 0.045012 *  \n",
       "hist         4.764e-01  1.008e-01   4.727 2.28e-06 ***\n",
       "newcar      -6.703e-01  4.623e-01  -1.450 0.147105    \n",
       "usedcar      7.830e-01  5.755e-01   1.361 0.173630    \n",
       "furn        -5.487e-02  4.780e-01  -0.115 0.908623    \n",
       "radiotv      8.473e-02  4.620e-01   0.183 0.854492    \n",
       "educ        -8.672e-01  5.896e-01  -1.471 0.141351    \n",
       "retrain      2.284e-01  5.271e-01   0.433 0.664745    \n",
       "amt         -1.525e-04  4.976e-05  -3.064 0.002186 ** \n",
       "sav          2.379e-01  7.006e-02   3.395 0.000686 ***\n",
       "emp          5.648e-02  8.857e-02   0.638 0.523673    \n",
       "instrate    -3.521e-01  9.981e-02  -3.527 0.000420 ***\n",
       "malediv     -5.518e-01  4.449e-01  -1.240 0.214802    \n",
       "malesingle   5.595e-01  2.374e-01   2.357 0.018411 *  \n",
       "malemarwid   8.168e-02  3.421e-01   0.239 0.811311    \n",
       "coapp       -8.291e-01  5.111e-01  -1.622 0.104779    \n",
       "guar         7.445e-01  4.563e-01   1.631 0.102801    \n",
       "presres     -1.008e-01  9.679e-02  -1.042 0.297500    \n",
       "realest      1.915e-01  2.466e-01   0.776 0.437475    \n",
       "propnone    -1.797e-01  4.564e-01  -0.394 0.693857    \n",
       "age          1.827e-02  1.019e-02   1.792 0.073173 .  \n",
       "other       -3.604e-01  2.362e-01  -1.526 0.126976    \n",
       "rent        -2.345e-01  5.621e-01  -0.417 0.676537    \n",
       "ownres      -5.753e-02  5.371e-01  -0.107 0.914702    \n",
       "numcred     -2.412e-01  1.868e-01  -1.291 0.196741    \n",
       "job         -3.661e-02  1.648e-01  -0.222 0.824244    \n",
       "numdep      -3.114e-01  2.904e-01  -1.072 0.283523    \n",
       "tel          2.516e-01  2.268e-01   1.109 0.267366    \n",
       "for.         1.536e+00  8.062e-01   1.905 0.056781 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 916.30  on 749  degrees of freedom\n",
       "Residual deviance: 689.55  on 719  degrees of freedom\n",
       "AIC: 751.55\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3D <- glm(resp~., data=credit_train, family=binomial)\n",
    "summary(model3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3E (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log Lik.' -344.7769 (df=31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log likelihood of model\n",
    "logLik(model3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3F (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE  40  18\n",
       "  TRUE   35 157"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "predict3F <- predict(model3D, credit_test, type=\"response\")\n",
    "table(predict3F>0.5, credit_test$resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3G (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.788"
      ],
      "text/latex": [
       "0.788"
      ],
      "text/markdown": [
       "0.788"
      ],
      "text/plain": [
       "[1] 0.788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model accuracy\n",
    "(40+157)/(40+35+18+157)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3H (c)\n",
    "\n",
    "For *Model3H*, $AIC=750.24$ which is comparable to *Model3D*'s $AIC=751.55$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = resp ~ chkacct + dur + hist + amt + sav + instrate + \n",
       "    malesingle + age + for. - 1, family = binomial, data = credit_train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.5475  -0.8448   0.4505   0.7671   1.8101  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error z value Pr(>|z|)    \n",
       "chkacct     5.977e-01  8.075e-02   7.402 1.34e-13 ***\n",
       "dur        -1.820e-02  9.416e-03  -1.933 0.053291 .  \n",
       "hist        3.887e-01  8.303e-02   4.682 2.84e-06 ***\n",
       "amt        -1.388e-04  4.374e-05  -3.175 0.001499 ** \n",
       "sav         2.184e-01  6.581e-02   3.318 0.000907 ***\n",
       "instrate   -3.168e-01  8.001e-02  -3.959 7.52e-05 ***\n",
       "malesingle  4.671e-01  1.927e-01   2.424 0.015344 *  \n",
       "age         1.318e-02  7.300e-03   1.805 0.071051 .  \n",
       "for.        1.420e+00  7.882e-01   1.802 0.071539 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1039.72  on 750  degrees of freedom\n",
       "Residual deviance:  732.24  on 741  degrees of freedom\n",
       "AIC: 750.24\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3H <- glm(resp~chkacct+dur+hist+amt+sav+instrate+malesingle+age+for.-1,\n",
    "               data=credit_train, family=binomial)\n",
    "summary(model3H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3I (c)\n",
    "\n",
    "Based on AIC score alone, *Model3H* is preferable to *Model3D*, albeit very slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3J (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE  33  15\n",
       "  TRUE   42 160"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "predict3J <- predict(model3H, credit_test, type=\"response\")\n",
    "table(predict3J>0.5, credit_test$resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3K (c)\n",
    "\n",
    "Based on $FPR$ (Type I), $Model3D = 0.533$ and $Model3D = 0.56$. Hence, *Model3D* is slightly preferred over *Model3H*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.466666666666667"
      ],
      "text/latex": [
       "0.466666666666667"
      ],
      "text/markdown": [
       "0.466666666666667"
      ],
      "text/plain": [
       "[1] 0.4666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.56"
      ],
      "text/latex": [
       "0.56"
      ],
      "text/markdown": [
       "0.56"
      ],
      "text/plain": [
       "[1] 0.56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model3D FPR\n",
    "35/(40+35)\n",
    "# model3H FPR\n",
    "42/(33+42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3L (c)\n",
    "\n",
    "Based on $FNR$ (Type II), $Model3D = 0.103$ and $Model3D = 0.085$. Hence, *Model3D* is slightly preferred over *Model3H*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.102857142857143"
      ],
      "text/latex": [
       "0.102857142857143"
      ],
      "text/markdown": [
       "0.102857142857143"
      ],
      "text/plain": [
       "[1] 0.1028571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0857142857142857"
      ],
      "text/latex": [
       "0.0857142857142857"
      ],
      "text/markdown": [
       "0.0857142857142857"
      ],
      "text/plain": [
       "[1] 0.08571429"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model3D FNR\n",
    "18/(157+18)\n",
    "# model3H FNR\n",
    "15/(160+15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3M (C)\n",
    "\n",
    "$AUC_{3D} = 0.829$ and $AUC_{3H} = 0.783$. Hence, *Model3D* is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "An object of class \"performance\"\n",
       "Slot \"x.name\":\n",
       "[1] \"None\"\n",
       "\n",
       "Slot \"y.name\":\n",
       "[1] \"Area under the ROC curve\"\n",
       "\n",
       "Slot \"alpha.name\":\n",
       "[1] \"none\"\n",
       "\n",
       "Slot \"x.values\":\n",
       "list()\n",
       "\n",
       "Slot \"y.values\":\n",
       "[[1]]\n",
       "[1] 0.8292571\n",
       "\n",
       "\n",
       "Slot \"alpha.values\":\n",
       "list()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "An object of class \"performance\"\n",
       "Slot \"x.name\":\n",
       "[1] \"None\"\n",
       "\n",
       "Slot \"y.name\":\n",
       "[1] \"Area under the ROC curve\"\n",
       "\n",
       "Slot \"alpha.name\":\n",
       "[1] \"none\"\n",
       "\n",
       "Slot \"x.values\":\n",
       "list()\n",
       "\n",
       "Slot \"y.values\":\n",
       "[[1]]\n",
       "[1] 0.782781\n",
       "\n",
       "\n",
       "Slot \"alpha.values\":\n",
       "list()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model3D AUROC\n",
    "ROCRpredict3D <- prediction(predict3F, credit_test$resp)\n",
    "ROCRperf3D <- performance(ROCRpredict3D, measure=\"auc\")\n",
    "ROCRperf3D\n",
    "\n",
    "# model3H AUROC\n",
    "ROCRpredict3H <- prediction(predict3J, credit_test$resp)\n",
    "ROCRperf3H <- performance(ROCRpredict3H, measure=\"auc\")\n",
    "ROCRperf3H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3N (c)\n",
    "\n",
    "Total profit incurred on test set is 5200 Deutschemark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "          0   1\n",
       "  FALSE  40  18\n",
       "  TRUE   35 157"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5200"
      ],
      "text/latex": [
       "5200"
      ],
      "text/markdown": [
       "5200"
      ],
      "text/plain": [
       "[1] 5200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recall Model3D confusion matrix (still assume threshold=0.5)\n",
    "table(predict3F>0.5, credit_test$resp)\n",
    "\n",
    "# calculate profit\n",
    "-300*35 + 100*157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3O (c)\n",
    "\n",
    "Duration of credit with lowest good credit risk is 36 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>chkacct</th><th scope=col>dur</th><th scope=col>hist</th><th scope=col>newcar</th><th scope=col>usedcar</th><th scope=col>furn</th><th scope=col>radiotv</th><th scope=col>educ</th><th scope=col>retrain</th><th scope=col>amt</th><th scope=col>...</th><th scope=col>age</th><th scope=col>other</th><th scope=col>rent</th><th scope=col>ownres</th><th scope=col>numcred</th><th scope=col>job</th><th scope=col>numdep</th><th scope=col>tel</th><th scope=col>for.</th><th scope=col>resp</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>819</th><td>0    </td><td>36   </td><td>2    </td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>0    </td><td>15857</td><td>...  </td><td>43   </td><td>0    </td><td>0    </td><td>1    </td><td>1    </td><td>3    </td><td>1    </td><td>0    </td><td>0    </td><td>1    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllll}\n",
       "  & chkacct & dur & hist & newcar & usedcar & furn & radiotv & educ & retrain & amt & ... & age & other & rent & ownres & numcred & job & numdep & tel & for. & resp\\\\\n",
       "\\hline\n",
       "\t819 & 0     & 36    & 2     & 0     & 0     & 0     & 0     & 0     & 0     & 15857 & ...   & 43    & 0     & 0     & 1     & 1     & 3     & 1     & 0     & 0     & 1    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | chkacct | dur | hist | newcar | usedcar | furn | radiotv | educ | retrain | amt | ... | age | other | rent | ownres | numcred | job | numdep | tel | for. | resp | \n",
       "|---|\n",
       "| 819 | 0     | 36    | 2     | 0     | 0     | 0     | 0     | 0     | 0     | 15857 | ...   | 43    | 0     | 0     | 1     | 1     | 3     | 1     | 0     | 0     | 1     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    chkacct dur hist newcar usedcar furn radiotv educ retrain amt   ... age\n",
       "819 0       36  2    0      0       0    0       0    0       15857 ... 43 \n",
       "    other rent ownres numcred job numdep tel for. resp\n",
       "819 0     0    1      1       3   1      0   0    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort test set from highest to lowest P(good credit risk)\n",
    "credit_test <- credit_test[names(sort(predict3F, T)),]\n",
    "# row ID with lowest good credit risk = 819\n",
    "\n",
    "# sort(predict3F, T)\n",
    "# names(sort(predict3F, T))\n",
    "# rownames(credit_test)\n",
    "\n",
    "# find dependent values for #819\n",
    "credit_test['819',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3P (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>965:</strong> 150"
      ],
      "text/latex": [
       "\\textbf{965:} 150"
      ],
      "text/markdown": [
       "**965:** 150"
      ],
      "text/plain": [
       "965 \n",
       "150 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>965:</strong> 7800"
      ],
      "text/latex": [
       "\\textbf{965:} 7800"
      ],
      "text/markdown": [
       "**965:** 7800"
      ],
      "text/plain": [
       " 965 \n",
       "7800 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAHgCAMAAACo6b1DAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"Cumulative profits v. Index (decreasing)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get discrete prediction (w/ threshold=0.5)\n",
    "# actually, it doesnt really matter now, as we shall see if we mess with...\n",
    "# ...the threshold value\n",
    "predict3P <- ifelse(sort(predict3F, T)>=0.0, 1, 0)\n",
    "\n",
    "# get profit of each individual row\n",
    "profits <- ifelse(predict3P==0, 0, ifelse(credit_test$resp==0, -300, 100))\n",
    "\n",
    "# get cumsum of profits\n",
    "cum_profits <- cumsum(profits)\n",
    "\n",
    "# get max profit point\n",
    "which(cum_profits==max(cum_profits)) # this get the index\n",
    "# cum_profits[\"965\"] # this gets the profit value\n",
    "# cum_profits[150] # this ALSO gets the profit value\n",
    "cum_profits[which(cum_profits==max(cum_profits))]\n",
    "\n",
    "# plot cumsum v. index\n",
    "plot(cum_profits, type=\"l\", main=\"Cumulative profits v. Index (decreasing)\")\n",
    "abline(0,0,lty=2) # breakeven line\n",
    "\n",
    "# ?sort\n",
    "# ?cumsum\n",
    "# ?which"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3Q (c)\n",
    "\n",
    "Credit should be lent to those with at least $71.9\\%$ probability of having a good credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>965:</strong> 0.718749471961773"
      ],
      "text/latex": [
       "\\textbf{965:} 0.718749471961773"
      ],
      "text/markdown": [
       "**965:** 0.718749471961773"
      ],
      "text/plain": [
       "      965 \n",
       "0.7187495 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get prediction value at max(cum_profits)\n",
    "predict3F[\"965\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question quatre\n",
    "### Part 4A (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t25 obs. of  9 variables:\n",
      " $ YEAR  : int  1916 1920 1924 1928 1932 1936 1940 1944 1948 1952 ...\n",
      " $ DEM   : Factor w/ 18 levels \"Carter\",\"Clinton\",..: 18 3 4 15 14 14 14 14 17 16 ...\n",
      " $ REP   : Factor w/ 17 levels \"Coolidge\",\"Dewey\",..: 11 9 1 10 10 12 17 2 2 4 ...\n",
      " $ INC   : int  1 1 -1 -1 -1 1 1 1 1 1 ...\n",
      " $ RUN   : int  1 0 -1 0 -1 1 1 1 1 0 ...\n",
      " $ DUR   : num  0 1 0 -1 -1.25 0 1 1.25 1.5 1.75 ...\n",
      " $ GROWTH: num  2.23 -11.46 -3.87 4.62 -14.35 ...\n",
      " $ GOOD  : int  3 0 10 7 4 9 8 0 0 7 ...\n",
      " $ WIN   : int  1 -1 -1 -1 1 1 1 1 1 -1 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "14"
      ],
      "text/latex": [
       "14"
      ],
      "text/markdown": [
       "14"
      ],
      "text/plain": [
       "[1] 14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11"
      ],
      "text/latex": [
       "11"
      ],
      "text/markdown": [
       "11"
      ],
      "text/plain": [
       "[1] 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pres <- read.csv(\"csv/presidential.csv\")\n",
    "str(pres)\n",
    "\n",
    "# get no. of democrat winnings\n",
    "NROW(pres$WIN[pres$WIN==1])\n",
    "\n",
    "# get no. of republican winnings\n",
    "NROW(pres$WIN[pres$WIN==-1])\n",
    "# subset(pres, pres$REP==\"Nixon\")\n",
    "# pres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part 4B (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   Carter   Clinton       Cox     Davis   Dukakis      Gore  Humphrey   Johnson \n",
       "        2         2         1         1         1         1         1         1 \n",
       "  Kennedy     Kerry  McGovern   Mondale     Obama Roosevelt     Smith Stevenson \n",
       "        1         1         1         1         2         4         1         2 \n",
       "   Truman    Wilson \n",
       "        1         1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  Coolidge      Dewey       Dole Eisenhower       Ford     G.Bush   G.W.Bush \n",
       "         1          2          1          2          1          2          2 \n",
       " Goldwater    Harding     Hoover     Hughes     Landon     McCain      Nixon \n",
       "         1          1          2          1          1          1          3 \n",
       "    Reagan     Romney     Wilkie \n",
       "         2          1          1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get number of presidential terms for democrats\n",
    "table(pres$DEM)\n",
    "\n",
    "# get number of presidential terms for republicans\n",
    "table(pres$REP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4C (c)\n",
    "\n",
    "- Null hypothesis: $H_0: Q_{DEM} - Q_{REP} = 0$\n",
    "- Null hypothesis: $H_1: Q_{DEM} - Q_{REP} \\neq 0$\n",
    "- p-value is $0.7494$\n",
    "- Unable to reject null hypothesis, hence we can conclude there is no significant difference between the number of good terms for DEM and REP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  pres$GOOD[pres$INC == 1] and pres$GOOD[pres$INC == -1]\n",
       "t = -0.32362, df = 21.196, p-value = 0.7494\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -2.854816  2.085585\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       " 4.615385  5.000000 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?t.test\n",
    "\n",
    "t.test(pres$GOOD[pres$INC==1], pres$GOOD[pres$INC==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4D (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pres$WININC <- ifelse(pres$INC==pres$WIN,1,0)\n",
    "# pres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4E (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of times incumbent party has won\n",
    "length(pres$WININC[pres$WININC==1])\n",
    "\n",
    "# Number of times incumbent party has won\n",
    "length(pres$WININC[pres$WININC==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4F (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = WININC ~ GROWTH, family = binomial, data = pres)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.8657  -0.9044   0.6222   0.8386   1.5112  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)   0.2435     0.5249   0.464   0.6427  \n",
       "GROWTH        0.2585     0.1381   1.871   0.0613 .\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 32.671  on 24  degrees of freedom\n",
       "Residual deviance: 26.365  on 23  degrees of freedom\n",
       "AIC: 30.365\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'log Lik.' -13.18257 (df=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'log Lik.' 1.883144e-06 (df=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-13.1825680673068"
      ],
      "text/latex": [
       "-13.1825680673068"
      ],
      "text/markdown": [
       "-13.1825680673068"
      ],
      "text/plain": [
       "[1] -13.18257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4F <- glm(WININC~GROWTH, data=pres, family=binomial)\n",
    "summary(model4F)\n",
    "logLik(model4F)\n",
    "exp(logLik(model4F))\n",
    "\n",
    "# manual calculation\n",
    "yes_odds <- exp(0.2435+0.2585*pres$GROWTH[pres$WININC==1])\n",
    "no_odds <- exp(0.2435+0.2585*pres$GROWTH[pres$WININC==0])\n",
    "yes <- log((yes_odds)/(1+yes_odds))\n",
    "no <- log(1/(1+no_odds))\n",
    "sum(yes)+sum(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4G (c)\n",
    "\n",
    "**Growth** variable is significant at the $0.1$ level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4H (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalise 'WIN' binary variable\n",
    "pres$WINNORM <- ifelse(pres$WIN==1, 1, 0)\n",
    "\n",
    "# normalise \"Growth\" variable\n",
    "pres$GROWTHNORM <- ifelse(pres$INC==1,\n",
    "                          ifelse(pres$GROWTH>=0, pres$GROWTH, pres$GROWTH),\n",
    "                          ifelse(pres$GROWTH>=0, -pres$GROWTH, -pres$GROWTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4I (c)\n",
    "\n",
    "$AIC=29.406$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>YEAR</th><th scope=col>DEM</th><th scope=col>REP</th><th scope=col>INC</th><th scope=col>RUN</th><th scope=col>DUR</th><th scope=col>GROWTH</th><th scope=col>GOOD</th><th scope=col>WIN</th><th scope=col>WININC</th><th scope=col>WINNORM</th><th scope=col>GROWTHNORM</th><th scope=col>GOODNORM</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1916      </td><td>Wilson    </td><td>Hughes    </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td>  2.229   </td><td> 3        </td><td> 1        </td><td>1         </td><td>1         </td><td>  2.229   </td><td>  3       </td></tr>\n",
       "\t<tr><td>1920      </td><td>Cox       </td><td>Harding   </td><td> 1        </td><td> 0        </td><td> 1.00     </td><td>-11.463   </td><td> 0        </td><td>-1        </td><td>0         </td><td>0         </td><td>-11.463   </td><td>  0       </td></tr>\n",
       "\t<tr><td>1924      </td><td>Davis     </td><td>Coolidge  </td><td>-1        </td><td>-1        </td><td> 0.00     </td><td> -3.872   </td><td>10        </td><td>-1        </td><td>1         </td><td>0         </td><td>  3.872   </td><td>-10       </td></tr>\n",
       "\t<tr><td>1928      </td><td>Smith     </td><td>Hoover    </td><td>-1        </td><td> 0        </td><td>-1.00     </td><td>  4.623   </td><td> 7        </td><td>-1        </td><td>1         </td><td>0         </td><td> -4.623   </td><td> -7       </td></tr>\n",
       "\t<tr><td>1932      </td><td>Roosevelt </td><td>Hoover    </td><td>-1        </td><td>-1        </td><td>-1.25     </td><td>-14.350   </td><td> 4        </td><td> 1        </td><td>0         </td><td>1         </td><td> 14.350   </td><td> -4       </td></tr>\n",
       "\t<tr><td>1936      </td><td>Roosevelt </td><td>Landon    </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td> 11.682   </td><td> 9        </td><td> 1        </td><td>1         </td><td>1         </td><td> 11.682   </td><td>  9       </td></tr>\n",
       "\t<tr><td>1940      </td><td>Roosevelt </td><td>Wilkie    </td><td> 1        </td><td> 1        </td><td> 1.00     </td><td>  3.913   </td><td> 8        </td><td> 1        </td><td>1         </td><td>1         </td><td>  3.913   </td><td>  8       </td></tr>\n",
       "\t<tr><td>1944      </td><td>Roosevelt </td><td>Dewey     </td><td> 1        </td><td> 1        </td><td> 1.25     </td><td>  4.122   </td><td> 0        </td><td> 1        </td><td>1         </td><td>1         </td><td>  4.122   </td><td>  0       </td></tr>\n",
       "\t<tr><td>1948      </td><td>Truman    </td><td>Dewey     </td><td> 1        </td><td> 1        </td><td> 1.50     </td><td>  3.214   </td><td> 0        </td><td> 1        </td><td>1         </td><td>1         </td><td>  3.214   </td><td>  0       </td></tr>\n",
       "\t<tr><td>1952      </td><td>Stevenson </td><td>Eisenhower</td><td> 1        </td><td> 0        </td><td> 1.75     </td><td>  0.997   </td><td> 7        </td><td>-1        </td><td>0         </td><td>0         </td><td>  0.997   </td><td>  7       </td></tr>\n",
       "\t<tr><td>1956      </td><td>Stevenson </td><td>Eisenhower</td><td>-1        </td><td>-1        </td><td> 0.00     </td><td> -1.252   </td><td> 5        </td><td>-1        </td><td>1         </td><td>0         </td><td>  1.252   </td><td> -5       </td></tr>\n",
       "\t<tr><td>1960      </td><td>Kennedy   </td><td>Nixon     </td><td>-1        </td><td> 0        </td><td>-1.00     </td><td>  0.674   </td><td> 5        </td><td> 1        </td><td>0         </td><td>1         </td><td> -0.674   </td><td> -5       </td></tr>\n",
       "\t<tr><td>1964      </td><td>Johnson   </td><td>Goldwater </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td>  5.030   </td><td> 9        </td><td> 1        </td><td>1         </td><td>1         </td><td>  5.030   </td><td>  9       </td></tr>\n",
       "\t<tr><td>1968      </td><td>Humphrey  </td><td>Nixon     </td><td> 1        </td><td> 0        </td><td> 1.00     </td><td>  5.045   </td><td> 7        </td><td>-1        </td><td>0         </td><td>0         </td><td>  5.045   </td><td>  7       </td></tr>\n",
       "\t<tr><td>1972      </td><td>McGovern  </td><td>Nixon     </td><td>-1        </td><td>-1        </td><td> 0.00     </td><td>  5.834   </td><td> 4        </td><td>-1        </td><td>1         </td><td>0         </td><td> -5.834   </td><td> -4       </td></tr>\n",
       "\t<tr><td>1976      </td><td>Carter    </td><td>Ford      </td><td>-1        </td><td> 0        </td><td>-1.00     </td><td>  3.817   </td><td> 5        </td><td> 1        </td><td>0         </td><td>1         </td><td> -3.817   </td><td> -5       </td></tr>\n",
       "\t<tr><td>1980      </td><td>Carter    </td><td>Reagan    </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td> -3.583   </td><td> 5        </td><td>-1        </td><td>0         </td><td>0         </td><td> -3.583   </td><td>  5       </td></tr>\n",
       "\t<tr><td>1984      </td><td>Mondale   </td><td>Reagan    </td><td>-1        </td><td>-1        </td><td> 0.00     </td><td>  5.550   </td><td> 8        </td><td>-1        </td><td>1         </td><td>0         </td><td> -5.550   </td><td> -8       </td></tr>\n",
       "\t<tr><td>1988      </td><td>Dukakis   </td><td>G.Bush    </td><td>-1        </td><td> 0        </td><td>-1.00     </td><td>  2.402   </td><td> 5        </td><td>-1        </td><td>1         </td><td>0         </td><td> -2.402   </td><td> -5       </td></tr>\n",
       "\t<tr><td>1992      </td><td>Clinton   </td><td>G.Bush    </td><td>-1        </td><td>-1        </td><td>-1.25     </td><td>  3.035   </td><td> 3        </td><td> 1        </td><td>0         </td><td>1         </td><td> -3.035   </td><td> -3       </td></tr>\n",
       "\t<tr><td>1996      </td><td>Clinton   </td><td>Dole      </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td>  3.315   </td><td> 4        </td><td> 1        </td><td>1         </td><td>1         </td><td>  3.315   </td><td>  4       </td></tr>\n",
       "\t<tr><td>2000      </td><td>Gore      </td><td>G.W.Bush  </td><td> 1        </td><td> 0        </td><td> 1.00     </td><td>  2.031   </td><td> 7        </td><td> 1        </td><td>1         </td><td>1         </td><td>  2.031   </td><td>  7       </td></tr>\n",
       "\t<tr><td>2004      </td><td>Kerry     </td><td>G.W.Bush  </td><td>-1        </td><td>-1        </td><td> 0.00     </td><td>  2.086   </td><td> 2        </td><td>-1        </td><td>1         </td><td>0         </td><td> -2.086   </td><td> -2       </td></tr>\n",
       "\t<tr><td>2008      </td><td>Obama     </td><td>McCain    </td><td>-1        </td><td> 0        </td><td>-1.00     </td><td> -1.787   </td><td> 2        </td><td> 1        </td><td>0         </td><td>1         </td><td>  1.787   </td><td> -2       </td></tr>\n",
       "\t<tr><td>2012      </td><td>Obama     </td><td>Romney    </td><td> 1        </td><td> 1        </td><td> 0.00     </td><td>  1.422   </td><td> 1        </td><td> 1        </td><td>1         </td><td>1         </td><td>  1.422   </td><td>  1       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllll}\n",
       " YEAR & DEM & REP & INC & RUN & DUR & GROWTH & GOOD & WIN & WININC & WINNORM & GROWTHNORM & GOODNORM\\\\\n",
       "\\hline\n",
       "\t 1916       & Wilson     & Hughes     &  1         &  1         &  0.00      &   2.229    &  3         &  1         & 1          & 1          &   2.229    &   3       \\\\\n",
       "\t 1920       & Cox        & Harding    &  1         &  0         &  1.00      & -11.463    &  0         & -1         & 0          & 0          & -11.463    &   0       \\\\\n",
       "\t 1924       & Davis      & Coolidge   & -1         & -1         &  0.00      &  -3.872    & 10         & -1         & 1          & 0          &   3.872    & -10       \\\\\n",
       "\t 1928       & Smith      & Hoover     & -1         &  0         & -1.00      &   4.623    &  7         & -1         & 1          & 0          &  -4.623    &  -7       \\\\\n",
       "\t 1932       & Roosevelt  & Hoover     & -1         & -1         & -1.25      & -14.350    &  4         &  1         & 0          & 1          &  14.350    &  -4       \\\\\n",
       "\t 1936       & Roosevelt  & Landon     &  1         &  1         &  0.00      &  11.682    &  9         &  1         & 1          & 1          &  11.682    &   9       \\\\\n",
       "\t 1940       & Roosevelt  & Wilkie     &  1         &  1         &  1.00      &   3.913    &  8         &  1         & 1          & 1          &   3.913    &   8       \\\\\n",
       "\t 1944       & Roosevelt  & Dewey      &  1         &  1         &  1.25      &   4.122    &  0         &  1         & 1          & 1          &   4.122    &   0       \\\\\n",
       "\t 1948       & Truman     & Dewey      &  1         &  1         &  1.50      &   3.214    &  0         &  1         & 1          & 1          &   3.214    &   0       \\\\\n",
       "\t 1952       & Stevenson  & Eisenhower &  1         &  0         &  1.75      &   0.997    &  7         & -1         & 0          & 0          &   0.997    &   7       \\\\\n",
       "\t 1956       & Stevenson  & Eisenhower & -1         & -1         &  0.00      &  -1.252    &  5         & -1         & 1          & 0          &   1.252    &  -5       \\\\\n",
       "\t 1960       & Kennedy    & Nixon      & -1         &  0         & -1.00      &   0.674    &  5         &  1         & 0          & 1          &  -0.674    &  -5       \\\\\n",
       "\t 1964       & Johnson    & Goldwater  &  1         &  1         &  0.00      &   5.030    &  9         &  1         & 1          & 1          &   5.030    &   9       \\\\\n",
       "\t 1968       & Humphrey   & Nixon      &  1         &  0         &  1.00      &   5.045    &  7         & -1         & 0          & 0          &   5.045    &   7       \\\\\n",
       "\t 1972       & McGovern   & Nixon      & -1         & -1         &  0.00      &   5.834    &  4         & -1         & 1          & 0          &  -5.834    &  -4       \\\\\n",
       "\t 1976       & Carter     & Ford       & -1         &  0         & -1.00      &   3.817    &  5         &  1         & 0          & 1          &  -3.817    &  -5       \\\\\n",
       "\t 1980       & Carter     & Reagan     &  1         &  1         &  0.00      &  -3.583    &  5         & -1         & 0          & 0          &  -3.583    &   5       \\\\\n",
       "\t 1984       & Mondale    & Reagan     & -1         & -1         &  0.00      &   5.550    &  8         & -1         & 1          & 0          &  -5.550    &  -8       \\\\\n",
       "\t 1988       & Dukakis    & G.Bush     & -1         &  0         & -1.00      &   2.402    &  5         & -1         & 1          & 0          &  -2.402    &  -5       \\\\\n",
       "\t 1992       & Clinton    & G.Bush     & -1         & -1         & -1.25      &   3.035    &  3         &  1         & 0          & 1          &  -3.035    &  -3       \\\\\n",
       "\t 1996       & Clinton    & Dole       &  1         &  1         &  0.00      &   3.315    &  4         &  1         & 1          & 1          &   3.315    &   4       \\\\\n",
       "\t 2000       & Gore       & G.W.Bush   &  1         &  0         &  1.00      &   2.031    &  7         &  1         & 1          & 1          &   2.031    &   7       \\\\\n",
       "\t 2004       & Kerry      & G.W.Bush   & -1         & -1         &  0.00      &   2.086    &  2         & -1         & 1          & 0          &  -2.086    &  -2       \\\\\n",
       "\t 2008       & Obama      & McCain     & -1         &  0         & -1.00      &  -1.787    &  2         &  1         & 0          & 1          &   1.787    &  -2       \\\\\n",
       "\t 2012       & Obama      & Romney     &  1         &  1         &  0.00      &   1.422    &  1         &  1         & 1          & 1          &   1.422    &   1       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "YEAR | DEM | REP | INC | RUN | DUR | GROWTH | GOOD | WIN | WININC | WINNORM | GROWTHNORM | GOODNORM | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1916       | Wilson     | Hughes     |  1         |  1         |  0.00      |   2.229    |  3         |  1         | 1          | 1          |   2.229    |   3        | \n",
       "| 1920       | Cox        | Harding    |  1         |  0         |  1.00      | -11.463    |  0         | -1         | 0          | 0          | -11.463    |   0        | \n",
       "| 1924       | Davis      | Coolidge   | -1         | -1         |  0.00      |  -3.872    | 10         | -1         | 1          | 0          |   3.872    | -10        | \n",
       "| 1928       | Smith      | Hoover     | -1         |  0         | -1.00      |   4.623    |  7         | -1         | 1          | 0          |  -4.623    |  -7        | \n",
       "| 1932       | Roosevelt  | Hoover     | -1         | -1         | -1.25      | -14.350    |  4         |  1         | 0          | 1          |  14.350    |  -4        | \n",
       "| 1936       | Roosevelt  | Landon     |  1         |  1         |  0.00      |  11.682    |  9         |  1         | 1          | 1          |  11.682    |   9        | \n",
       "| 1940       | Roosevelt  | Wilkie     |  1         |  1         |  1.00      |   3.913    |  8         |  1         | 1          | 1          |   3.913    |   8        | \n",
       "| 1944       | Roosevelt  | Dewey      |  1         |  1         |  1.25      |   4.122    |  0         |  1         | 1          | 1          |   4.122    |   0        | \n",
       "| 1948       | Truman     | Dewey      |  1         |  1         |  1.50      |   3.214    |  0         |  1         | 1          | 1          |   3.214    |   0        | \n",
       "| 1952       | Stevenson  | Eisenhower |  1         |  0         |  1.75      |   0.997    |  7         | -1         | 0          | 0          |   0.997    |   7        | \n",
       "| 1956       | Stevenson  | Eisenhower | -1         | -1         |  0.00      |  -1.252    |  5         | -1         | 1          | 0          |   1.252    |  -5        | \n",
       "| 1960       | Kennedy    | Nixon      | -1         |  0         | -1.00      |   0.674    |  5         |  1         | 0          | 1          |  -0.674    |  -5        | \n",
       "| 1964       | Johnson    | Goldwater  |  1         |  1         |  0.00      |   5.030    |  9         |  1         | 1          | 1          |   5.030    |   9        | \n",
       "| 1968       | Humphrey   | Nixon      |  1         |  0         |  1.00      |   5.045    |  7         | -1         | 0          | 0          |   5.045    |   7        | \n",
       "| 1972       | McGovern   | Nixon      | -1         | -1         |  0.00      |   5.834    |  4         | -1         | 1          | 0          |  -5.834    |  -4        | \n",
       "| 1976       | Carter     | Ford       | -1         |  0         | -1.00      |   3.817    |  5         |  1         | 0          | 1          |  -3.817    |  -5        | \n",
       "| 1980       | Carter     | Reagan     |  1         |  1         |  0.00      |  -3.583    |  5         | -1         | 0          | 0          |  -3.583    |   5        | \n",
       "| 1984       | Mondale    | Reagan     | -1         | -1         |  0.00      |   5.550    |  8         | -1         | 1          | 0          |  -5.550    |  -8        | \n",
       "| 1988       | Dukakis    | G.Bush     | -1         |  0         | -1.00      |   2.402    |  5         | -1         | 1          | 0          |  -2.402    |  -5        | \n",
       "| 1992       | Clinton    | G.Bush     | -1         | -1         | -1.25      |   3.035    |  3         |  1         | 0          | 1          |  -3.035    |  -3        | \n",
       "| 1996       | Clinton    | Dole       |  1         |  1         |  0.00      |   3.315    |  4         |  1         | 1          | 1          |   3.315    |   4        | \n",
       "| 2000       | Gore       | G.W.Bush   |  1         |  0         |  1.00      |   2.031    |  7         |  1         | 1          | 1          |   2.031    |   7        | \n",
       "| 2004       | Kerry      | G.W.Bush   | -1         | -1         |  0.00      |   2.086    |  2         | -1         | 1          | 0          |  -2.086    |  -2        | \n",
       "| 2008       | Obama      | McCain     | -1         |  0         | -1.00      |  -1.787    |  2         |  1         | 0          | 1          |   1.787    |  -2        | \n",
       "| 2012       | Obama      | Romney     |  1         |  1         |  0.00      |   1.422    |  1         |  1         | 1          | 1          |   1.422    |   1        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   YEAR DEM       REP        INC RUN DUR   GROWTH  GOOD WIN WININC WINNORM\n",
       "1  1916 Wilson    Hughes      1   1   0.00   2.229  3    1  1      1      \n",
       "2  1920 Cox       Harding     1   0   1.00 -11.463  0   -1  0      0      \n",
       "3  1924 Davis     Coolidge   -1  -1   0.00  -3.872 10   -1  1      0      \n",
       "4  1928 Smith     Hoover     -1   0  -1.00   4.623  7   -1  1      0      \n",
       "5  1932 Roosevelt Hoover     -1  -1  -1.25 -14.350  4    1  0      1      \n",
       "6  1936 Roosevelt Landon      1   1   0.00  11.682  9    1  1      1      \n",
       "7  1940 Roosevelt Wilkie      1   1   1.00   3.913  8    1  1      1      \n",
       "8  1944 Roosevelt Dewey       1   1   1.25   4.122  0    1  1      1      \n",
       "9  1948 Truman    Dewey       1   1   1.50   3.214  0    1  1      1      \n",
       "10 1952 Stevenson Eisenhower  1   0   1.75   0.997  7   -1  0      0      \n",
       "11 1956 Stevenson Eisenhower -1  -1   0.00  -1.252  5   -1  1      0      \n",
       "12 1960 Kennedy   Nixon      -1   0  -1.00   0.674  5    1  0      1      \n",
       "13 1964 Johnson   Goldwater   1   1   0.00   5.030  9    1  1      1      \n",
       "14 1968 Humphrey  Nixon       1   0   1.00   5.045  7   -1  0      0      \n",
       "15 1972 McGovern  Nixon      -1  -1   0.00   5.834  4   -1  1      0      \n",
       "16 1976 Carter    Ford       -1   0  -1.00   3.817  5    1  0      1      \n",
       "17 1980 Carter    Reagan      1   1   0.00  -3.583  5   -1  0      0      \n",
       "18 1984 Mondale   Reagan     -1  -1   0.00   5.550  8   -1  1      0      \n",
       "19 1988 Dukakis   G.Bush     -1   0  -1.00   2.402  5   -1  1      0      \n",
       "20 1992 Clinton   G.Bush     -1  -1  -1.25   3.035  3    1  0      1      \n",
       "21 1996 Clinton   Dole        1   1   0.00   3.315  4    1  1      1      \n",
       "22 2000 Gore      G.W.Bush    1   0   1.00   2.031  7    1  1      1      \n",
       "23 2004 Kerry     G.W.Bush   -1  -1   0.00   2.086  2   -1  1      0      \n",
       "24 2008 Obama     McCain     -1   0  -1.00  -1.787  2    1  0      1      \n",
       "25 2012 Obama     Romney      1   1   0.00   1.422  1    1  1      1      \n",
       "   GROWTHNORM GOODNORM\n",
       "1    2.229      3     \n",
       "2  -11.463      0     \n",
       "3    3.872    -10     \n",
       "4   -4.623     -7     \n",
       "5   14.350     -4     \n",
       "6   11.682      9     \n",
       "7    3.913      8     \n",
       "8    4.122      0     \n",
       "9    3.214      0     \n",
       "10   0.997      7     \n",
       "11   1.252     -5     \n",
       "12  -0.674     -5     \n",
       "13   5.030      9     \n",
       "14   5.045      7     \n",
       "15  -5.834     -4     \n",
       "16  -3.817     -5     \n",
       "17  -3.583      5     \n",
       "18  -5.550     -8     \n",
       "19  -2.402     -5     \n",
       "20  -3.035     -3     \n",
       "21   3.315      4     \n",
       "22   2.031      7     \n",
       "23  -2.086     -2     \n",
       "24   1.787     -2     \n",
       "25   1.422      1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = WINNORM ~ INC + RUN + DUR + GROWTHNORM + GOODNORM, \n",
       "    family = binomial, data = pres)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6418  -0.3862   0.0302   0.3889   1.6105  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept)  0.04699    0.63096   0.074    0.941\n",
       "INC         -0.17339    3.06255  -0.057    0.955\n",
       "RUN          1.96642    1.71162   1.149    0.251\n",
       "DUR         -2.08399    1.77249  -1.176    0.240\n",
       "GROWTHNORM   0.50456    0.31041   1.625    0.104\n",
       "GOODNORM     0.10169    0.29263   0.348    0.728\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 34.296  on 24  degrees of freedom\n",
       "Residual deviance: 17.406  on 19  degrees of freedom\n",
       "AIC: 29.406\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalise \"Good\" variable (here, it depends on how you model the values)\n",
    "# pres$GOODNORM <- ifelse(pres$INC==1,\n",
    "#                         ifelse(pres$GOOD>7.5, pres$GOOD-7.5, pres$GOOD-7.5),\n",
    "#                         ifelse(pres$GOOD>7.5, 7.5-pres$GOOD, 7.5-pres$GOOD))\n",
    "pres$GOODNORM <- ifelse(pres$INC==1, pres$GOOD, -pres$GOOD)\n",
    "\n",
    "pres\n",
    "model4I <- glm(WINNORM~INC+RUN+DUR+GROWTHNORM+GOODNORM, data=pres, family=binomial)\n",
    "summary(model4I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4J (c)\n",
    "\n",
    "The three least significant variables are **INC**, **GOOD**, **(intercept)**. AIC of reduced model is $23.748$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4K (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = WINNORM ~ DUR + GROWTHNORM + RUN - 1, family = binomial, \n",
       "    data = pres)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.46675  -0.36836   0.04492   0.47750   1.73580  \n",
       "\n",
       "Coefficients:\n",
       "           Estimate Std. Error z value Pr(>|z|)  \n",
       "DUR         -1.7852     1.0876  -1.641   0.1007  \n",
       "GROWTHNORM   0.4690     0.2774   1.691   0.0909 .\n",
       "RUN          2.0638     0.9772   2.112   0.0347 *\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 34.657  on 25  degrees of freedom\n",
       "Residual deviance: 17.748  on 22  degrees of freedom\n",
       "AIC: 23.748\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4K <- glm(WINNORM~DUR+GROWTHNORM+RUN-1, data=pres, family=binomial)\n",
    "summary(model4K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4L (c) !\n",
    "\n",
    "Smallest significance level I would reject $H_0: DUR = 0$ is if the cutoff is $0.1$. However, given how close it is, one might be tempted to leave it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4M (c)\n",
    "\n",
    "I will prefer **Model4K** over **Model4I** as **4K** has a lower AIC score and comparably-close residual deviances. By dropping the variables that has are less interpretable, the model obtained is clearer and less susceptible to \"noise\" from errorneous readings or readings with wide fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4N (c)\n",
    "\n",
    "$INC=1$, $RUN=0$, $DUR=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4O (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.300043539724165"
      ],
      "text/latex": [
       "\\textbf{1:} 0.300043539724165"
      ],
      "text/markdown": [
       "**1:** 0.300043539724165"
      ],
      "text/plain": [
       "        1 \n",
       "0.3000435 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict4O <- predict(model4K, data.frame(INC=1, RUN=0, DUR=1, GROWTHNORM=2), type=\"response\")\n",
    "\n",
    "# probability of Clinton winning\n",
    "predict4O"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
